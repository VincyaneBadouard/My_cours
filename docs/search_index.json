[["index.html", "My cours My personal courses Preface", " My cours My personal courses Vincyane Badouard 2023-01-30 Preface This book contains my personal courses. Some are in French, some in English, or both…sorry. Have a nice reading. Vincyane "],["introduction.html", "Introduction", " Introduction Blah. "],["fonctions-bien-sympatiques-trés-cher.html", "Cours 1 Fonctions bien sympatiques trés cher 1.1 Conseils 1.2 Tips de codeur 1.3 Packages inédits! 1.4 Mes raccourcis claviers 1.5 Symbol/name, charactères, variable/objet tout le bazar 1.6 Charger les données 1.7 Corection préliminaires des données 1.8 Transformation de données ! 1.9 Histoire de characters 1.10 La syntaxe qui fait ch**r, du balai ! 1.11 Comparaison de tables 1.12 Tirage 1.13 Yo ! arrange mes données ! 1.14 Donne moi des infos sur mes données 1.15 Calcul informatif 1.16 sf package 1.17 Eh oh c’est moi qui décide ! illustre moi ça comme il faut ! 1.18 Télécharger mon bébé dans le bon format, au bon endroit ! 1.19 Nettoyage 1.20 Boucle 1.21 Les objets 1.22 Condition 1.23 Logical Operators 1.24 Stan - Modelo - Bayes 1.25 Faire de la biblio comme une déesse 1.26 Date &amp; time", " Cours 1 Fonctions bien sympatiques trés cher Description : du R base, des fonctions de “base”, du tidyverse. Pour du data.table voir le cours concerné. ICI JE METS JUSTE LE NOM DES FONCTIONS, MAIS FAUT CHERCHER SUR INTERNET/LES PAGES D’AIDE LES MODALITES D’UTILISATION !! 1.1 Conseils Eviter de donner le meme nom au pipe que la base qu’on utilise dedans, ça écrase les données, et c’est la galere pour les reccuperer Les fonctions tidy sont pas faites pour s’imbriquer. Utiliser des fonctions base à l’int des fcts tidy. Qd un prblm est trop gros, découper le travail (ex: faire des soustables) 1.2 Tips de codeur Selectionner tout ce qu’il ya dans la parenthèse/crochet/accolade : double clic à l’interieur de la 1ère/dernière Mesurer le temps d’exécution d’un code : system.time ou microbenchmark (fct1,fct2) pour des codes trés courts. Ce sont les médianes des temps de calcul qu’il faut comparer. détacher un package de l’environnement : unloadNamespace() connaitre le code d’une fct : trace(pkgname::fct, edit=T) (obt &lt;- code) : affiche l’objet Empecher l’affichage d’un message d’erreur : try( , silent=TRUE) # no error printed Progress bar : pb = txtProgressBar(min = 0, max = length(ind), style = 3) then close(pb) debuger : traceback() Tracer un warning : options(warn = 2) (le transforme en erreur) quand fin de debuger options(warn = 0) 1.3 Packages inédits! Shiny pour trouver des packages R dans le milieu forestier : ForestAnalysisInR::launchRFA() 1.4 Mes raccourcis claviers Tout selectionner : Ctrl + A Indenter : Ctrl + I Recherche sur toutes les pages du projet : Ctrl + Shift + F (on peut faire du replace !) %in% : Ctrl + Shift + I (nécéssite un package) %&gt;% : Ctrl + Shift + M 1.5 Symbol/name, charactères, variable/objet tout le bazar nom d’objet -&gt; ce nom en characteres : deparse(substitute(var)) chaine de characteres -&gt; nom d’objet : as.name(“name”) chaine de characteres -&gt; objet : get(“var”) 1.6 Charger les données Chemin absolu : écriture de l’entièreté du chemin Chemin relatif : ~ = le dossier du setwd ./ = là où je suis Les .rmd ont leur propre racine, donc pas celle de leur projet. « ../ = dossier parent (du niv de dessus) et je mets autant de ../ que de niveau à remonter. Puis tabulation pour qu’il propose mes fichiers. Stocker mon chemin relatif dans un objet « path ». file.path(path, “dossier”, “file”) function pour lire mon chemin stocké. fonction pour aller chercher le fichier : nomObjt &lt;- file.choose() !!!!!!Environment &gt; import dataset &gt; tjrs spécifier le séparateur (delimiter) et le marqueur de décimale (locale &gt; decimal mark)!!!!!!!!! (franchement ça fait trop de la m**rd sinon) Importer avec les accents : locale = locale(encoding = “latin1”) Importer du shapefile (shp) : readORG(dsn = “/path/to/your/file”, layer = “filename”) ou shapefile(“path/to/your/file.shp”) 1.7 Corection préliminaires des données Corriger les arbres non touvées mais vivants dans inventaires : package forestdata sur github ecofog 1.8 Transformation de données ! De character à factor : mutate(Vernacular = factor(as.character(Vernacular))) Séparer 1 colonne en plsrs : **separate(data, col à séparer, sep = “_“, into = c(nom des new col), remove = F)** remove = F pour conserver la colonne qu’on sépare Combiner des colonnes en une : unite(col1, col2, col = “sp”, sep = ” “, remove = T) La même qd ya pas de séparateur : mutate(variable = substr(x, start, stop)) ou StrLeft(x, n) StrRight(x, n) en partant de la fin. -n pour enlever n paramètre Recoder une variable : mutate(var = recode(var, “1” = “A” , “2” = “B”)) le nouveau code derière le = si ya erreur essayer : “‘1’ = ‘A’ ; ‘2’ = ‘B’” guillemets double et simple et point virgule Changer une variable sous condition : mutate(var = ifelse(condition, si oui, sinon)) Sous plusieurs conditions : séparer les conditions d’un &amp; Changer le nombre de décimales : format(x, digits = 0, scientific = F) ou round(x, digits = 0) effectuer par ligne : rowise Remplir une colonne à partir d’une fonction dont l’input est une table : do() déplie la une sous-table existant dans une table : unnest() Encode a column in utf8 : tidyft::utf8_encoding(datatable, colname) 1.9 Histoire de characters Detect special charcters (logical) : x &lt;- “!” grepl(‘[[:punct:]]’, x) # TRUE if there are any special character, FALSE if not. Remove special characters : x &lt;- “a-,_b/” **gsub(“[[:punct:]]”, ““, x)** x la chaine de characters à modifier, entre” ” mettre par quoi remplacer les special charcters enlevés (ou ne rien mettre) Extraire un element numeric dans une chaîne de characters : extract_numeric(var) Mettre le nom d’un objet sous forme de characters : deparse(substitute(obj)) Extraire un élément d’une chaine de characters : si data\\(idtree = &quot;site_plot&quot; **data\\)site = tstrsplit(data\\(idtree, split = &quot;_&quot;)[[1]]** 1er elmt **data\\)plot = tstrsplit(data$idtree, split = “_“)[[2]]** 2nd afficher un data.frame en characters : a &lt;- data.frame(x=runif(4), y=runif(4), z=runif(4)) b &lt;- capture.output(a) c &lt;- paste(b, &quot;\\n&quot;, sep=&quot;&quot;) cat(&quot;Your data set is:\\n&quot;, c, &quot;\\n&quot;) 1.10 La syntaxe qui fait ch**r, du balai ! Enlever un espace avant et/ou apres un character : trimws(x, which = c(“both”, “left”, “right”)) Mettre en minuscule/majuscule : tolower()/toupper() 1ère lettre de l’expression en majuscule : str_to_sentence() Enlever accent : sub(“é”,“e”,vector)) 1.11 Comparaison de tables diffdf(,) 1.12 Tirage Tirer aléatoirement n individus sans remplacement : sample_n(n, replace = F) 1.13 Yo ! arrange mes données ! Vincyane la base… ## Quand tu veux passer une collone de df en argument de fonction : ## V0 column_name &lt;- &quot;Position&quot; ## character string in an object column &lt;- inventory[,column_name] ## character vector line_nonna &lt;- which(!is.na(column)) ## which rows different of NA subinventory &lt;- inventory[line_nonna,] ## filter base version ## V1 column_name &lt;- &quot;Position&quot; column &lt;- inventory[,column_name] nonna &lt;- !is.na(column) ## logical vector subinventory &lt;- inventory[nonna,] ## take only the TRUE ## V2 column_name &lt;- &quot;Position&quot; inventory[!is.na(inventory[,column_name]),] %&gt;% st_as_sf(wkt = column_name) ## Vdplyr col_name &lt;- deparse(substitute(var)) ## object name to this name in character(get() pour faire l&#39;inverse) inventory %&gt;% filter(!is.na( {{ var }} )) %&gt;% ## {{var}} pour réccupérer l&#39;objet mis en argument &quot;var&quot; st_as_sf(wkt = col_name) ## quand t&#39;as besoin du nom de la colonne en charactère #ou modif_var &lt;- function(data, nom_variable){ data %&gt;% dplyr::mutate(nouveau_nom = !!rlang::sym(nom_variable)+1) } Inverser lignes &amp; colonnes (retourner) (transposer) : t() Mettre une colonne en colonne “rownames” : column_to_rownames(data, varàdéplacer) Metrre l’information de plusieurs colonnes en 1 : melt() Inverse : dcast(col1 + col2 ~ newcol) Ne prendre qu’une partie des données : filter() ou subset() Si on veut garder les NA, comme filter les vire d’office, rajouter | is.na(var) Pour filtrer beaucoup de valeurs d’une même var: values &lt;- c(“Tom”, “Lynn”) vecteur de n’importe quoi filter(dat, var %in% values) Ne pas prendre une partie des données (valeurs) : filter(!(Vernacular %in% remove)) (enlever remove dans vernacular) Quand dans un booléen les Na dérangent, utiliser plutot %in% que == (ex: a %in% TRUE) Enlever des colonnes : select(-colname) Réaliser les opérations suivantes par groupes de modalités : group_by Créer une variable résumant les effectifs des éléments d’une variable : summarise(N = n()) ou count() Effectifs par ordre croissant : arrange(N) Effectifs par ordre décroissant : arrange(desc(N)) Ordonner un vecteur : sort(, decreasing = FALSE) Ranger par ordre alphabétique : d’abord transformer la variable character en factor, puis arrange(var) Selectionner les n valeurs maximales : top_n Afficher les 30 1ères lignes : slice(1:30) Changer ordre des colonnes : select(c(a, y, x, b : w)) Séparer une base de données, selon un facteur, en une liste de bases de données : split(data, data$fact) Enlever les lignes en plusieurs exemplaires/connaitre les valeurs que peut prendre une colonnne : unique() Savoir si ttes les valeurs d’une colonne sont les mêmes: length(unique(data\\(var)) == 1** ou **all(data\\)var == data$var[1]) = est-ce que toutes les valeurs sont égales à la 1ère Répliquer une ligne n fois : do.call(“rbind”, replicate(n, df, simplify = FALSE)) 1.14 Donne moi des infos sur mes données pH[pH&gt;7] : afficher les ph&gt;7 length(pH[pH&gt;7]) : combien de ph&gt;7 data[pH&gt;7,] : afficher les lignes dont les ph&gt;7 which(x==a) : renvoie les indices (n°de lignes) de x pour lesquels le résultat de l’opération logique est vrai Indicer selon une modalité : data[data$var ==“modalite”,] Nombre de NA dans 1 colonne : sum(is.na(data$x_num)) Nombre de lignes ayant pour valeur “truc” dans telle variable sum(as.numeric(data$var == “truc”), na.rm = TRUE) pcq as.numeric transforme un vecteur de booléen en vecteur de 0 et 1. Nombre de NA dans le jeu de de données, dans chaque colonne : colSums(is.na(data)) est-ce que tt ça est vrai : all() au moins 1 vrai : any() ne prend pas de liste (enfin si mais il n’est pas cntent)! renvoyer les éléments dupliqué : duplicated() (booléen) data[!duplicated(data$var), ] (dataframe) anyDuplicated Générer la numérotation/les id des lignes : seq.int(nrow(df)) 1.15 Calcul informatif Faire la somme/moyenne/autre de chaque ligne/colonne : apply(data, c(1,2), sum) 1 : par ligne ou 2 : par colonne Appliquer une fonction sur une liste/vecteur : lapply(liste, function(elementdelaliste) la fonction dépendante de l’élement) ou lapply(liste, function, autres arguments de la fct) ex : multiply &lt;- function(x, factor, div) { (x * factor)/div } lapply(list(1,2,3), multiply, x = 5, factor = 3) # the list is for the &quot;div&quot; argument lapply(a, function(element) bcDiversity(element$N, q = 1, Correction = &quot;Best&quot;)) ptit tips : la version fonction d’extraction d’élément d’un objet ($) : getElement(object, var) ex : lapply(x, function(x) x$var) = lapply(x, function(x) getElement(x, &quot;var&quot;)) = lapply(x, getElement, &quot;var&quot;) Appliquer une fonction sur plsrs listes/vecteurs : mapply(function(X,Y) {la fonction(X, Y)}, X=list1, Y=list2, SIMPLIFY = F) SIMPLIFY = F : laisse la structure initiale de la liste map functions family font apriori la même chose que les apply avec plus de possiblités et + rapides car écrites en C (https://r4ds.had.co.nz/iteration.html) Les map ne produisent que des vecteurs, pas de matrice) Quand onotre map ne fctne pas il ne renvoie rien. Pour savoir ce qu’il ne va pas : map(safely(fct)) qui renvoie le résultat et le message d’erreur 1.16 sf package Passer d’un sf à un dataframe (supprimer la col géométrie) : st_geometry(sf) &lt;- NULL sfg to sfc : st_sfc(sfg) sfc to sfg : st_point(as.numeric(unlist(sfc))) (ex ici point) MULTIPOINT to POINT : st_cast(st_sfc(mutipoint), “POINT”, group_or_split = TRUE) Simplification d’objet : st_cast(objet, “objt + simple” (ex : polygon to linestring) Attribuer un crs à un objt sf ou sfc : st_set_crs(objtsanscrs, st_crs(objtaveccrs)) st_union ne préserve pas l’ordre des géométries dans la géométrie finale, il faut utiliser : objt_sf_12 &lt;- objt_sf_1 %&gt;% rbind(objt_sf_2) objt_sf_12 &lt;- do.call(c, st_geometry(objt_sf_12)) 1.17 Eh oh c’est moi qui décide ! illustre moi ça comme il faut ! Faire des graphs ggplot en clic bouton : esquisse::esquisser() Des plots tout beau prêts à publier : ggpubr Relier le label au point quand c’est pas visible : geom_text_repel Pour pouvoir faire un facet_wrap (plsrs graphs en 1 figure), il est plus aisé de transformer sa table de ‘Wide-format’ à ‘long-format’ (https://seananderson.ca/2013/10/19/reshape/): melt() Séparer un facet_wrap en plusieurs pages : facet_wrap_paginate() Echelles différentes sur un facet : scales = “free” “free_x” “free_y” or “fixed” qd on veut personnaliser : on crée un data pour un geom_blank : blank_data &lt;- data.frame(group = c(“var1”, “var1”, “var2”, “var2”), x = c(min commun, max commun, min commun, max commun), y = c(min commun, max commun, min commun, max commun)) puis geom_blank(data = blank_data, aes(x = x, y = y)) Gradient de couleurs : colorRampPalette(c(“blue”, “white”, “red”))(4) 4 = nbr de catégories ou scale_fill_gradient2(low=“blue”, high=“red”, mid = “white”) Voir les palettes : RColorBrewer::display.brewer.all() 1.18 Télécharger mon bébé dans le bon format, au bon endroit ! PNG : png() avant commande du plot &amp; dev.off() après commande du plot ggsave() compresser : save(objt, file = “objt.rda”, compress = “xz”) 1.19 Nettoyage Enlever un élément de l’environement : remove() Vider tt l’envrmt global : rm(list = ls()) ls() renvoie ts les objets de l’envmt 1.20 Boucle Output : créer un objet vide de la classe, voire de la taille que l’on souhaite pour notre output (+ rapide) chaine de charactère vide : ““ vecteur/liste : vector(“numeric”, length(x)), ou juste vector(), list() Quand on ne connait pas la longeur de l’output apriori, on peut l’aggrandir progressivement dans le corps de la boucle : output &lt;- c(output, action qu’on boucle) ou on stocke les outputs de chaque itération dans un élément d’une liste crée en amont (vector(“list”, length(x))), puis qd la loop est finie on unlist (+efficace). En résumé pour les gros outputs, il vaut mieux créer des outputs plus légers à chaque iteration puis tout coller ensemble après la boucle (-lourd). Sequence : créer un vecteur dans lequel puiser s’il n’existe déjà pour agir sur chaque col d’un df : seq_along(df) boucler sur indice, value ou names Body : Pour chaque valeur que peut prendre trait dans All_traits : for(trait in All_traits){} resultat &lt;- rep(NA, 3) for(i in seq_len(3)) { resultat[i] &lt;- i } utiliser [[]] plutot que [] même pour les vecteurs seq_along() : permet dans le cas où la sequence est de taille 0 ou 1 de bien avoir un output de cette taille sinon avec 1:length(1 ou 0) on optiendra 1 0 ou 1 1 faire une boucle dont les résultats sont mis dans une liste: foreach() Boucle while : boucle jusq’à ce que la condition soit fausse. Peut être utilisée lorsqu’on ne connait pas la longueur de la séquence. while (condition) { ## body } Arrêter la boucle : break() Arreter l’itération actuelle et asser à la prochaine : next() 1.21 Les objets 1.21.0.1 des infos sur mon objet Présence d’une variable “varName” %in% names(df) Type : class(a), pour ttes les variables d’une table lapply(data, class) Structure : str(a, 1) 1 c’est le niveau de structure, yen a plsrs, c’est pas obligatoire 1.21.0.2 List “a” la liste. + Voir les éléments de la liste : a$ + Indicer une liste : a[[position]] Transposer une liste (inverser la tructure) : purr::transpose() 1.21.0.3 Fonction function(arguments){ operation1 operation2 return() ## préciser ce que la fonction doit renvoyer } 1.22 Condition Les if sont des booléens qui vérifient si la “condition” est “TRUE”, donc il n’est pas nécessaire “x == TRUE” mais seulement “x” ou “!x” + if(condition) {action} + if(condition1 &amp;&amp; condition2) { expression } + if(condition1 || condition2) { expression } Dans les if else la place des brackets est importante: if(case1) { expression1 } else { expression2 } if(case1) { expression1 } else if(case2) { expression2 } ... else last.expression ifelse(condition, expression1, expression2) vectorized version of the if() statement. Warning: ifelse() is designed to work with vectors and matrices – not data frames. 1.23 Logical Operators c(T, F, T) | c(F, F, T) ## TRUE FALSE TRUE c(T, F, T) || c(F, F, T) ## TRUE c(F, F, T) || c(F, F, T) ## FALSE c(F, F, T) || c(T, F, T) ## TRUE ## |/&amp; to compare each value of different bolean vectors ## ||/&amp;&amp; to compare single value conditions 1.24 Stan - Modelo - Bayes Chercher une fct dans Rstan : lookup(“bernoulli”) 1.25 Faire de la biblio comme une déesse package bibliometrix 1.26 Date &amp; time convertir une date (y, m, d) en année numeric : as.numeric(format(ExactDate, “%Y”)) Wrong system time : Sys.time() Sys.timezone() To find our time zone : OlsonNames() Set the new time zone : Sys.setenv(TZ = “America/Cayenne”) To change permanently : change time zone of your computer "],["datatable-functions.html", "Cours 2 datatable functions 2.1 Sources 2.2 Pourquoi data.table 2.3 Syntax 2.4 Create a data.table 2.5 Convert a data.frame or list to a data.table 2.6 Punctuation 2.7 Subset rows : 2.8 Extract columns 2.9 Summarize 2.10 Compute columns 2.11 Change column class 2.12 Group 2.13 Common grouped operations 2.14 A sequence operation on a datatable", " Cours 2 datatable functions 2.1 Sources https://www.rdocumentation.org/packages/data.table/versions/1.14.2 (R doc) https://larmarange.github.io/analyse-R/manipulations-avancees-avec-data-table.html (French, trés bien!) https://linogaliana.netlify.app/post/datatable/datatable-intro/ (French, trop bien !!) https://www.listendata.com/2016/10/r-data-table.html (efficace) https://cran.r-project.org/web/packages/data.table/vignettes/datatable-intro.html (vignette) https://stackoverflow.com/questions/tagged/data.table (stackoverflow) https://cran.r-project.org/web/packages/data.table/vignettes/datatable-faq.html (frequent questions in dt) 2.2 Pourquoi data.table https://dreamrs.github.io/talks/20180528_RAddicts_datatable.pdf data.table est particulièrement adapté aux données volumineuses (plus de 1Go) où l’utilisation de dplyr est vivement déconseillée data.table est beaucoup plus rapide et puissant que dplyr ne dépend que de R-base, importe uniquement le package “methods” 2.3 Syntax dt[i, j, by] dt : data.table i : rows j : columns/expressions by : grouped columns ces 3 éléments ne sont pas toujours présents Les crochets permettent de ne pas utiliser le “$”. data.table also = to data.frame 2.4 Create a data.table library(data.table) dt &lt;- data.table(a = c(2, 1), b = c(&quot;a&quot;, &quot;b&quot;)) dt[, `:=`(c = 1 , d = 2, e = c(1, 2))] dt &lt;- dt[, -c(2)] ## remove b column (il faut assigner sinon il ne l&#39;enregistre pas) dt[, e := NULL] ## là non dt[, c, by = .(a)] # group dt[, c, keyby = .(a)] ## group and order 2.5 Convert a data.frame or list to a data.table setDT(df) (preferred) or as.data.table(df) setDF(dt) to return in data.frame 2.6 Punctuation les fonctions commençant par set ou contenant l’opérateur := n’ont pas besoin d’être réassigné à l’objet avec “&lt;-”. C’est mieux car ne garde pas de copie en mémoire. le . est un raccourci de list entre [ ] mais pas en dehors := ou :=() (“assignation par référence”) permet de modifier une variable en assignation directe, donc pas besoin de “&lt;-” -&gt; + rapide et très économe en mémoire vive 2.7 Subset rows : by rows positions : dt[1:2, ] by values in one or more columns : dt[a &gt; 5, ] both : dt[1:2][a &gt; 5] (ne marche pas pour calculer une colonne, utiliser ifelse) values between two values : dt[a %between% c(2,6)] patern match : dt[a %like% “dep”] ! ne renvoie pas les NA contrairement au data.frame ! La virgule n’est pas obligatoire si pas de colonnes à spécifier. 2.8 Extract columns Les colonnes sont des listes. by position : dt[, c(2)], prefix “-” to drop by names : dt[, .(b, c)] le point est un raccourci de list dans les [] pas en dehors. return as vector : dt[, b] ou dt[[b]] return as data.table : dt[, list(b)] On ne peut pas directement selctionner un var par sa position ou avec une chaine de charactères car compris comme des cstes : dt[, c(“a”), with = FALSE] dt[, !c(“a”, “b”), with = FALSE] remove “a” and “b” columns dt[, c(2:4), with = FALSE] To find patern (like grepl()) %like% ex : dt[,names(dt) %like% “dep”, with=FALSE] patern : “dep” %between% 2.9 Summarize dt[, .(x = sum(a))] create a data.table with new columns based on the summarized values of rows. Summary functions ex : mean(), median(), min(), max(), etc dt[, lapply(.SD, mean), .SDcols = c(“a”, “b”)] for several columns dt[, lapply(.SD, mean)] for all the columns dt[, sapply(.SD, function(x) c(mean=mean(x), median=median(x)))] multiple statistics .N pour obtenir le nombres d’observations ,by = par sous-groupe 2.10 Compute columns := permet de modifier une variable en assignation directe, donc pas besoin de “&lt;-”. (“c”) pour dire que ce sont des colonnes existantes et non des nouvelles a creer dt[, c := 1 + 2] : compute a column based on an expression (c = col name) dt[a == 1, c := 1 + 2] : compute a column based on an expression but only for a subset of rows Si on veut mettre des NA ! : NA_integer_, NA_real_, NA_character_ (mettre juste NA pose des problèmes de classe) dt[, :=(c = 1 , d = 2)] : compute multiple columns based on separate expressions (se créent en meme temps donc ne peut pas dépendre de l’autre) ou dt[ , c(“newcol1”, “newcol2”) := list(col1 * 10, col2 * 20)] With an ifelse : dt[, c := ifelse(min &lt; 50, 1,0)] (1 if TRUE, 0 if FALSE) Delete a column : dt[, c := NULL] (trés rapide) Séparer 1 col en 2 : dt[, c(“cola”, “colb”) := tstrsplit(col, “_“, fixed = TRUE)] Unire 2 col en 1 : dt[, xy:= paste0(x,y)] ou dt[, xy:= paste(x,y, sep = “_“)] 2.11 Change column class dt[, b := as.integer(b)] 2.12 Group dt[, j, by = “colname”] : by 1 var dt[, j, by = .(a)] : group rows by values in specified columns (a the column). dt[, j, by = c(“var1”, “var2”, “var3”)] dt[, j, keyby = .(a)] : group and simultaneously order rows by values in specified columns. 2.13 Common grouped operations dt[, .(c = sum(b)), by = a] : summarize rows within groups. dt[, c := sum(b), by = a] : create a new column and compute rows within groups. dt[, .SD[1], by = a] : extract first row of groups. dt[, .SD[.N], by = a] : extract last row of groups. dt[, .(new = old, new = col1 + col2)] : rename a col, and compute another 2.14 A sequence operation on a datatable Pour enchaîner les opérations : dt[…][…] Règle : pas faire de lignes trop longues et crochet de fin d’op et celui de début de la prochaine doivent être accolé : ][**] IdTree = &quot;idTree&quot; Plot = &quot;plot&quot; SubPlot = &quot;subplot&quot; AssoVect &lt;- c(IdTree, Plot, SubPlot, TreeFieldNum) correspondances &lt;- unique(Data[, ..AssoVect]) ## &quot;..&quot; correspondances &lt;- unique(Data[, c(IdTree, Plot, SubPlot, TreeFieldNum), with = FALSE]) ## with = FALSE : the column names can be used as variables Cas plus générique : eval &amp; substitute eval() exécute une expression substitute() : attribut les valeurs, substitut les variables (=names=symbol) par leurs valeurs as.name() : refer to R object by their name -&gt; avoid conflict and work with user variables names df1 &lt;- data.table(sp = LETTERS[1:10], x = rnorm(10)) ## cas où l&#39;arg n&#39;a pas le même nom que la col df2 &lt;- data.table(species = LETTERS[1:10], var = rnorm(10)) ## cas où l&#39;arg a le même nom que la col species = &quot;sp&quot; var = &quot;x&quot; fun &lt;- function(df, species, var){ env &lt;- lapply(list(.species = species, .var = var), as.name) ## environment eval(substitute( { df[, p := paste(.species, .var)] df[, q := paste(.species, &quot;_&quot;, .var)] ## le . devant le nom n&#39;est pas nécessaire c&#39;est juste mieux de distinguer pour le codeur }, env)) return(df) } fun(df1, &quot;sp&quot;, &quot;x&quot;) ## cas où l&#39;arg n&#39;a pas le même nom que la col df1 fun(df2, &quot;species&quot;, &quot;var&quot;) ## cas où l&#39;arg a le même nom que la col df2 2.14.1 .SD (Subset of Data) .SD permet d’appliquer la même opération sur plusieurs colonnes. .SDcols : sélection des colonnes sur lesquelles appliquer l’opération (par défaut elles sont toutes prises) -&gt; syntaxe très puissante, compact et lisible 2.14.2 lapply+.SD pour des fonctions de statistiques descriptives ## fabriquer une table statistique DT[, lapply(.SD, min), .SDcol = &quot;a&quot;, by = c] mes_statistiques &lt;- function(x) return(c(mean(x), var(x), quantile(x, probs = c(.25,.5,.75)))) data_agregee &lt;- dt[, ## i lapply(.SD, mes_statistiques), ## j (expression) by = &quot;Species&quot;, ## by (group) .SDcols = c(&quot;Petal.Width&quot;,&quot;Petal.Length&quot;)] data_agregee[, &#39;stat&#39; := c(&quot;moyenne&quot;,&quot;variance&quot;,&quot;P25&quot;,&quot;P50&quot;,&quot;P75&quot;), by = &quot;Species&quot;] ## add a col to define the values in rows data_agregee 2.14.3 Des data.table poupées russes Facilite la parallélisation DT[, list(list(.SD)), by = Group] cl &lt;- makeCluster(2) DT[, clust := list(parLapplyLB(cl, V1, function(X){kmeans(X,2)$cluster}))] "],["spatial-data-cours.html", "Cours 3 Spatial data cours 3.1 Tips 3.2 Mapper des données", " Cours 3 Spatial data cours library(tidyverse) library(sf) 3.1 Tips Le CRS est souvent une source de bug : absent, pas le bon, contenant des accents 3.2 Mapper des données Mapper des points dont on a la longitude et la latitude : ggplot(mapping = aes(x = lon, y = lat)) + geom_point() ggmap : ajoute des couches d’images (fond de carte) téléchargées depuis des services de cartorgaphie en ligne. library(&quot;ggmap&quot;) east_canada &lt;- get_stamenmap(bbox = c(left=-81, right = -59, bottom = 44, top = 51),#boîte de coordonnées délimitant la carte à produire zoom = 6, #zoom = niv de détails (2 suffisant pour une carte du monde) maptype = &quot;terrain&quot;) # type de carte ggmap(east_canada) + geom_point(data = weather, mapping = aes(x = lon, y = lat)) ## ou ggmap(east_canada, base_layer = ggplot(weather, aes(x = lon, y = lat))) + geom_point() ##base_layer permet d’effectuer des facettes et d’éviter de spécifier la source des données dans toutes les couches subséquentes. Maptype : - “terrain” : efficace mais peu esthétique - “toner-lite” : pour l’impression - “watercolor” : pour le web 3.2.1 Types de données spatiales Les données spatiales sont des données localisées dans un système de coordonnées de référence (CRS) Données vectorielles (en général en 2D, 3D si on prend en compte l’altitude: Données ponctuelles : points Données linéaires : série de points (route, rivière) Données de polygone : aire délimitée par des points (champ, bassin versant) Données raster: grille (image satellite où chaque pixel est associé à un recouvrement foliaire.) Données génériques : shapefiles et geojson Données spécialement conçus pour R : sf 3.2.2 ggplot geom_polygon : : pour créer des polygones coord_map geom_path() : pour créer des lignes geom_tile() : visualiser une grille -&gt; graphique de type “heatmap” *geom_sf() : pour afficher les objets sf Cartes intéractives (mode leaflet) : tmap_mode(“view”) Pour revenir en mode statique : tmap_mode(“plot”) 3.2.3 Les rasters = données (variable(s)) associées à une grille comprenant les combinaisons de longitudes et latitudes. Raster = * une en-tête : - syst de coordonnées de référence - l’origine : généralement les coordonnées du coin bas-gauche de la matrice (mais le package ‘raster’ prends le coin haut-gauche par défaut) - dimensions : nbr de colonnes, de lignes, la résolution de la taille des cellules * une matrice de cellules équidistantes (~pixels) : la matrice ne stocke qu’1 coordonnée de la cellule : l’origine -&gt; + efficace et rapide que le traitement des données vectorielles. 1 cellule = 1 ou plsrs valeurs, ou NA (numérique ou catégorique) = la valeur moyenne (ou majoritaire) de la zone qu’elle couvre. Cependant, dans certains cas, les valeurs sont en fait des estimations pour le centre de la cellule. l’information spatiale est implicitement donnée par l’étendue spatiale et le nombre de lignes et de colonnes dans lesquelles la zone est divisée. Les données raster sont en général continues (altitude, T°, densité de pop), mais peuvent-être aussi catégoriques (type de sol) mais dans ce cas une représentation vectorielle pourrait être plus appropriée. expand.grid() : créer une grille de paramêtres : associer des coordonées à une variable grid &lt;- expand.grid(lon = seq(from = -80, to = -60, by = 0.25), lat = seq(from = 45, to = 50, by = 0.25)) grid &lt;- grid %&gt;% mutate(z = 10*sin(lon*lat) - 0.01*lon^2 + 0.05*lat^2) # créer une variable spatialisée grid %&gt;% head() ggplot(grid, aes(lon, lat)) + geom_tile(aes(fill = z)) Géostatistique = étude statistique des variables spatiales 3.2.4 Les objets spatialisés en R 3.2.4.1 Données vectorielles Objets géoréférencés R (=variables (data.frame) liés à des coordonées (sfc)): sf Packages : sp, sf (mieux adapté au tidy) Transformer un dataframe en objet sf : st_as_sf() : - type de géométrie (geometry type: POINT (= sfg objets)), - les limites des objets (bbox: …), - le système de référence (epsg ou proj4string: …) - le tableau descriptif Revenir à une table non spatialisée : st_drop_geometry() Les objets sfg peuvent être créés avec : * un vecteurs numérique * une matrice * une liste plot(st_point(c(5, 2))) # XY point (2D) st_point(c(5, 2, 3)) # XYZ point (3D) st_point(c(5, 2, 1), dim = &quot;XYM&quot;) # XYM point st_point(c(5, 2, 3, 1)) # XYZM point ## the &#39;rbind&#39; function simplifies the creation of matrices ### MULTIPOINT multipoint_matrix = rbind(c(5, 2), c(1, 3), c(3, 4), c(3, 2)) plot(st_multipoint(multipoint_matrix)) ### LINESTRING linestring_matrix = rbind(c(1, 5), c(4, 4), c(4, 1), c(2, 2), c(3, 2)) plot(st_linestring(linestring_matrix)) ### POLYGON polygon_list = list(rbind(c(1, 5), c(2, 2), c(4, 1), c(4, 4), c(1, 5))) plot(st_polygon(polygon_list)) ### POLYGON with a hole polygon_border = rbind(c(1, 5), c(2, 2), c(4, 1), c(4, 4), c(1, 5)) polygon_hole = rbind(c(2, 4), c(3, 4), c(3, 3), c(2, 3), c(2, 4)) polygon_with_hole_list = list(polygon_border, polygon_hole) plot(st_polygon(polygon_with_hole_list)) ### MULTILINESTRING multilinestring_list = list(rbind(c(1, 5), c(4, 4), c(4, 1), c(2, 2), c(3, 2)), rbind(c(1, 2), c(2, 4))) plot(st_multilinestring((multilinestring_list))) ### MULTIPOLYGON multipolygon_list = list(list(rbind(c(1, 5), c(2, 2), c(4, 1), c(4, 4), c(1, 5))), list(rbind(c(0, 2), c(1, 2), c(1, 3), c(0, 3), c(0, 2)))) plot(st_multipolygon(multipolygon_list)) ### GEOMETRYCOLLECTION gemetrycollection_list = list(st_multipoint(multipoint_matrix), st_linestring(linestring_matrix)) plot(st_geometrycollection(gemetrycollection_list)) ##&gt; GEOMETRYCOLLECTION (MULTIPOINT (5 2, 1 3, 3 4, 3 2), ##&gt; LINESTRING (1 5, 4 4, 4 1, 2 2, 3 2)) 3.2.4.1.1 Simple feature columns (sfc) une sfc est une liste d’objets sfg, de meme type géométrique ou non. point1 = st_point(c(5, 2)) point2 = st_point(c(1, 3)) points_sfc = st_sfc(point1, point2) #st_sfc() crée une liste d&#39;objets sfg points_sfc st_geometry_type(points_sfc) sfc to sfg : st_point(as.numeric(unlist(sfc))) (ex ici point) st_read() : pour charger des données (ex:shapefiles) au format sf Les tableaux sf sont manipulables sous tydiverse. plot() : par défaut crée un multi-panel plot : un graph par variable. Pour ne ploter que les contours (la géométrie): quebec %&gt;% st_geometry() %&gt;% plot() # ou bien plot(st_geometry(quebec)), ou bien plot(quebec %&gt;% select(geometry)) Jointures spatiales (intersections de polygones, unions, différences) -&gt; 1 nouvelle géométrie Attribuer un crs à un objt sf ou sfc : st_set_crs(objtsanscrs, st_crs(objtaveccrs)) Exporter un tableau sf en format csv incluant la géométrie : st_write(obj = tableau,dsn = “tableau.csv”, layer_options = “GEOMETRY=AS_XY”) Si la géométrie n’est pas consituée de points, il faudra préalablement transformer les polygones en points avec st_cast() 3.2.4.2 Données raster Package : raster grilles svt enchasées dans des images tif géoréférencées. 1 image tif = 1 ou plsrs bandes (variables) raster() : importe des données raster à 1 bande (“names” dans les infos) brick() : importe des données raster à plsrs bandes (“names” dans les infos) stack() : permet de connecter plusieurs objets raster stockés dans différents fichiers ou plusieurs objets en mémoire Les informations des objets RasterLayer et RasterBrick peuvent être extraites par les fonctions : extent(), ncell(), nlayers() et crs(). La fonction plot() permet d’explorer les données en créant 1 graphique par bande. Les tif sont trés volumineux. Si l’on n’as pas besoin d’une si haute résolution, on peut simplifier le raster avec raster::aggregate() 3.2.4.3 Travailler sur du vectoriel &amp; du raster Le package “raster” ne supporte pas le format sf, il faut donc préalablement convertir en sp : poly_sp &lt;- as(poly, “Spatial”) (poly étant ici un polygone) 3.2.4.4 Opérations sur Raster Intersection (ce qu’il y a en commun) entre un polygone et un raster : mask() Découper (rectangulaire selon les limites de l’objet) : crop() Extraction : extract() ##Pour effectuer un calcul sur l’intérieur du polygone avec extract()… on spécifie le raster, le polygone et la fonction! extract(canopy, poly_sp, fun = mean) # &quot;canopy&quot; = raster, &quot;poly_sp&quot; = polygone 3.2.5 Shapefiles Contiennent plsrs fichiers : fichier .prj : informations du système de coordonnées 3.2.6 Systèmes de coordonnées de références (CRS) Le vérifier en UTM c’est en mètres 3.2.6.1 Système de coordonnées géographiques Valeurs : Longitude/latitude La Terre est représenté sphérique ou ellipsoïde (+juste). Modele ellipsoïde, 2 paramètres: - rayon équatorial - rayon polaire 3.2.6.2 Système de référence de coordonnées pojetées basé sur des coordonées catésiennes sur une surface plane. et basés sur les systèmes de coordonnées géographiques une origine axes x &amp; y une unité (ex: le mètre) "],["données-lidar.html", "Cours 4 Données LIDAR", " Cours 4 Données LIDAR LiDAR : “light detection and ranging” ou “laser imaging detection and ranging” Lumière d’un laser en général : visible, infrarouge ou ultraviolet Télémétrie : détermination de la distance d’un objet Principe d’écholocalisation : La distance est donnée par la mesure du délai entre l’émission d’une impulsion et la détection d’une impulsion réfléchie, connaissant la vitesse de la lumière. Mesure de la matière : isoler l’effet des différentes interactions entre la lumière et la matière le long du faisceau laser. On appelle « équation lidar » le bilan de liaison du lidar entre son émission et sa réception, c’est-à-dire l’énergie lumineuse E (en J) de l’impulsion rétrodiffusée par une cible (supposée lambertienne, i.e. qui diffuse la lumière uniformément) située à une distance z et captée par le lidar Emet de plusieurs dizaines à plusieurs centaines de milliers d’impulsions chaque seconde "],["c.html", "Cours 5 C++", " Cours 5 C++ Intérêt : + rapide Package Rcpp : simplifie l’intégration de code C++ dans R Inconvénients : difficile à débugger -&gt; n’y écrire que du code maitrisé et méritant cet effort Sous R : + préparation/vérification des données + traitement et la présentation des résultats. C++ : + dans un package (dossier “src”) + dans un doc C++ (.cpp) + dans RMarkdown avec insertion chunk Rcpp sourceCpp() : compilation du .cpp Créer une fonction C++ : calculer le double d’un vecteur numérique #include &lt;Rcpp.h&gt; using namespace Rcpp; // [[Rcpp::export]] NumericVector timesTwo(NumericVector x) { return x * 2; } -&gt; Une fct R du meme nom que la fct C++ s’est créée timesTwo(1:5) "],["rmarkdown.html", "Cours 6 Rmarkdown 6.1 Packages 6.2 Chunk", " Cours 6 Rmarkdown Reprise du cours de Sylvain Schmitt Autres cours: https://bookdown.org/yihui/rmarkdown-cookbook/ 6.1 Packages install.packages(c(&quot;rmarkdown&quot;, &quot;knitr&quot;, &quot;blogdown&quot;, &quot;tidyverse&quot;, &quot;citr&quot;)) texte ## Titre 6.1.1 Sous-titre Liste : chat chien oiseau Liste numérotée : Liste numérotée on peut laisser 1. et il met les bons numéros italique ou italique gras ou gras gras&amp;italique citation Pour passer à la ligne suivante/faire un nouveau paragraphe : finir par 2 espaces la ligne 6.2 Chunk Raccourci clavier pour générer un chunk : CTRL + ALT + I Chunk options : echo = F : ne pas voir le code eval = F : ne pas faire tourner le code include = F : ne pas afficher les sorties console Voir documentation le reste à voir dans le petit engrenage du chunk Afficher une valeur dans le texte : 1+2 = ‘r 1+2’ "],["spécifier-un-working-directory-différent-de-celui-du-fichier.html", "Cours 7 Spécifier un working directory différent de celui du fichier 7.1 Table 7.2 Figure 7.3 Equations 7.4 Des diagrammes avec Mermaid ! 7.5 Bibliographie 7.6 Références croisées 7.7 Cache", " Cours 7 Spécifier un working directory différent de celui du fichier knitr::opts_knit$set(root.dir = &#39;chemin&#39;) 7.1 Table ##la fonction &quot;kable&quot; dans &quot;knitr&quot; knitr::kable(head(cars), #les en-têtes de &quot;cars&quot; caption = &quot;Légende.&quot;) 7.2 Figure fig.cap = \"Caption.\" pour la légende d’une figure fig.height = 8, fig.width=4 pour la taille de la figure library(tidyverse) ggplot(cars, aes(speed, dist))+ geom_point() 7.3 Equations Dans le texte : \\(\\alpha\\), \\(\\gamma = \\alpha + \\beta\\) En bande centrale : \\[Y \\sim\\mathcal N(\\mu,\\sigma)\\frac{1}{1+e}\\] \\[Y \\sim \\mathcal N(\\frac{\\mu_s}{\\beta \\times X}, \\sigma^2)\\] Voir le latex maths wiki 7.4 Des diagrammes avec Mermaid ! https://github.blog/2022-02-14-include-diagrams-markdown-files-mermaid/ https://mermaid-js.github.io/mermaid/#/ 7.5 Bibliographie La bilbliographie est lu à partir d’un fichier .bib préciser dans l’en-tête YAML et peut être généré automatiquement avec Mendeley, Endnote, etc … On peut aussi préciser le formation de citation avec un fichier .csl défini en ligne pour chaque journal. La référence [@Cochrane2003] se fait avec @ + [ + code bib + ] mais on peut utiliser l’addin citr pour le faire de manière interactive. Je recommande même de définir un raccourcit clavier personnel pour facilement effectuer une citation (par exemple CTRL + SHIFT + G). Enfin on place un titre Référence à la fin du document après lequel se placera la bibliographie mise en forme. 7.6 Références croisées Les références croisées nécessite d’utiliser le package bookdown même sans faire un livre à partir des formats documents2. Elle se font avec SLASH + @ + ref + ( + type + : + nom du chunk + ). Par exemple je fais référence à la table ?? et la figure ??. knitr::kable(head(cars), caption = &quot;Ceci est une table.&quot;) ggplot(cars, aes(speed, dist)) + geom_point() 7.7 Cache Le cache vous permet d’enregistrer les sorties d’un fragment de code pour que lors des prochaines compilation il ne soit pas recalculer. Il créé un dossier _files et _cache avec les images R des objets du chunk et les figures respectives. Attention, si votre chunk dépend d’un chunk qui est mise à jour et que vous ne précisez pas la dépendance il ne sera pas mis à jour. Utilisez l’option dependson ou nettoyez le cache pour éviter cela. "],["github.html", "Cours 8 Github", " Cours 8 Github Un-commit (reverse commit) without losing the changes : https://stackoverflow.com/questions/19859486/how-to-un-commit-last-un-pushed-git-commit-without-losing-the-changes "],["bookdown.html", "Cours 9 Bookdown 9.1 Fichiers particuliers", " Cours 9 Bookdown R proj particulier pour le bookdown 9.1 Fichiers particuliers index.rmd : fichier pour indiquer le header de ts les fichiers, écrit la “préface” _bookdown.yml : def construction livre book_filename: &quot;My_cours&quot; delete_merged_file: true # supprimer le fichier intermediaire de la compilation language: ui: chapter_name: &quot;Cours &quot; output_dir: &quot;docs&quot; # dossier de stockage de la compilation _output.yml : def construction des sorties bookdown::gitbook: config: toc: before: | &lt;li&gt;&lt;a href=&quot;./&quot;&gt;My_cours&lt;/a&gt;&lt;/li&gt; after: | # lien &quot;source&quot; vers le dépot Github &lt;li&gt;&lt;a href=&quot;https://github.com/VincyaneBadouard/My_cours&quot; target=&quot;blank&quot;&gt;Source&lt;/a&gt;&lt;/li&gt; collapse: section # pour ne pas afficher les sous-parties ds le menu deroulant includes: in_header: hypothesis.html # permet les comentaires dans le doc (open review) before_body: open_review_block.html scroll_hillight: yes # mise en couleur qd on est dans la partie "],["intégration-continue.html", "Cours 10 Intégration continue 10.1 Travis 10.2 Codecov", " Cours 10 Intégration continue Intégration continue = confier à un service externe certaines taches (tests, production de docs, tricot) pour limiter la perte de temps. 10.1 Travis nécessaire d’ouvrir un compte sur le site possible de s’authentifier avec son compte GitHub Lien Travis-github : clé privée PAT (Personal Access Token) Créer un jeton : Settings &gt; Developer settings &gt; Personal access tokens &gt; Generate new token &gt; décrire “Travis” et donner l’autorisation “repo” &gt; Generate token et enregistrer le jeton qqpart, sinon c’est perdu. Mon jeton déjà créé : 2c731e9c305bb450d691bdea233ede3e7f7b1d88 a ne pas perdre Activation du dépôt: Sur le site de Travis &gt; settings &gt; settings du repository &gt; Name : GITHUB_TOKEN, Value : &gt; add La liste des dépôts GitHub est présentée. Pour en activer un, cliquer sur l’interrupteur gris à côté de son nom 10.1.1 Script de contrôle de Travis fichier: .travis.yml. 10.2 Codecov Evalue la proportion testé du code 1) nécessaire d’ouvrir un compte sur le site 2) possible de s’authentifier avec son compte GitHub "],["function-creation.html", "Cours 11 Function creation 11.1 Étapes de développement : 11.2 Structure : 11.3 Nommer ses arguments 11.4 Valeurs par défaut 11.5 évaluation de la fonction 11.6 Vérification de la classe des arguments 11.7 L’argument ‘fun’ 11.8 L’argument ‘…’ 11.9 Types de fonction 11.10 Retourner un résultat 11.11 Fonctions de message et d’arrêt de fonction 11.12 Interaction avec l’utilisateur 11.13 Iteration 11.14 Parallelisation 11.15 Choses à savoir 11.16 Débogage tips 11.17 Où écrire ses fcts ? 11.18 Comment les utiliser ? 11.19 Plusieurs fonctions internes - passation d’infos", " Cours 11 Function creation 11.1 Étapes de développement : Planifier le travail (pas de programmation encore) : définir clairement la tâche à accomplir par la fonction et la sortie qu’elle doit produire, prévoir les étapes à suivre afin d’effectuer cette tâche, identifier les arguments devant être fournis en entrée à la fonction. Développer le corps de la fonction Écrire le programme par étapes, d’abord sans former la fonction, en commentant bien le code et en travaillant sur des mini-données test. Pour chaque petite étape ou sous-tâche, tester interactivement si le programme produit le résultat escompté (tester souvent en cours de travail, ainsi il y a moins de débogage à faire). Créer la fonction à partir du programme développé. Documenter la fonction. Tester la fonction : sauvegarder nos tests et bien les structurer, car ils serviront souvent. Si nous rencontrons des comportements indésirables lors des tests, déboguer la fonction : cerner le ou les problèmes, apporter les correctifs nécessaires à la fonction (que ce soit dans son corps ou dans liste de ses arguments), adapter la documentation et les tests au besoin, faire tourner de nouveau les tests, répéter ces sous-étapes jusqu’à ce que les tests ne révèlent plus aucun problème à régler ou aucune amélioration à apporter. 11.2 Structure : nomdemafonction&lt;-function(variable1,variable2...) { #ici on met le contenu de la fonction (généralement on effectue des transformations aux variables passées en argument) return(Variabledesortie) ## il s&#39;agit du résultat que va renvoyer la fonction (non négligeable!)! c&#39;est bien le but d&#39;une fct! } #une fois la fonction créée on peut l&#39;utiliser: nomdemafonction(varA,varB,...) Une fct normalement constituée ne travaille directement que sur ses arguments et non sur les objets stockés dans la console. Tous les objets qui seront utilisés dans le script doivent avoir été créés dans le script. Les seules exceptions à cette règle sont les arguments qui eux sont définis dans l’en-tête. Exemple ## Calculer le coefficient de variation (CV) (=écart type/moyenne) d&#39;une série de valeur. cv &lt;- function(x){ ## x est un vecteur contenant une série de valeurs moy &lt;- mean(x) ## moyenne de x s &lt;- sd(x) ## ecart type de x rslt &lt;- s/moy ## calcul du CV rslt #la fonction retourne le résultat } 11.3 Nommer ses arguments Noms habituels : x, y, z: vectors. w: a vector of weights. df: a data frame. i, j: numeric indices (typically rows and columns). n: length, or number of rows. p: number of columns. Règle : Si les arguments des fonctions appelées sont donnés de la forme name = object, ils peuvent être écris dans n’importe quel ordre. Dans le cas contraire, il faut respecter l’ordre des arguments. fun1 &lt;- function(data, data.frame, graph, limit) { [function body omitted] } ## Alors la fonction peut être invoquée de plusieurs manières, par exemple: ans &lt;- fun1(d, df, TRUE, 20) ## arguments dans l&#39;ordre ans &lt;- fun1(data=d, limit=20, graph=TRUE, data.frame=df) ## arguments dans le désordre et donc nommés 11.4 Valeurs par défaut fun1 &lt;- function(data, data.frame, graph=TRUE, limit=20) { ... } #on attribue une valeur à l&#39;argument dès l&#39;écriture 11.5 évaluation de la fonction return() renvoie la dernière valeur calculée nom_de_fonction &lt;- function(arguments) { instructions return(valeur) #non négligeable! c&#39;est bien le but d&#39;une fct! } 11.6 Vérification de la classe des arguments class(x) 11.7 L’argument ‘fun’ = passer une fonction a une autre fonction en argument col_summary &lt;- function(df, fun) { out &lt;- vector(&quot;double&quot;, length(df)) for (i in seq_along(df)) { out[i] &lt;- fun(df[[i]]) } out } col_summary(df, median) col_summary(df, mean) 11.8 L’argument ‘…’ Il est possible d’utiliser le symbole ‘…’ (ellipsis) dans les paramètres d’une fct pour indiquer que tous les paramètres supplémentaires seront transmis aux autres fonctions internes. fun1 &lt;- function(data, data.frame, graph=TRUE, limit=20, ...) { [omitted statements] if (graph) par(pch=&quot;*&quot;, ...) [more omissions] } 11.9 Types de fonction 11.9.1 Appel récursif La récursivité est une démarche qui fait référence à l’objet-même de la démarche à un moment du processus (=poupée russe) Une fct peut s’appeller elle-même, tant qu’il existe une condition d’arrêt. ## Scalaire : nombre réel ## Vecteur : serie de valeurs ## Sur scalaire factorielle &lt;- function(n) { if (n==1) resultat &lt;- 1 ## scalaire booléen ## arrêt de la récursion (n=1 est la condition d&#39;arrêt) else resultat &lt;- factorielle(n-1)*n ## appel récursif (si n différent de 1) return(resultat) } ## Sur vecteur factorielle &lt;- function(n) { indice &lt;- (n == 1) ## vecteur de booléens if (all(indice)) return(n) ## arrêt de la récursion (n=1 est la condition d&#39;arrêt) n[!indice] &lt;- n[!indice]*factorielle(n[!indice] - 1) ## appel récursif (si n différent de 1) return(n) } 11.9.2 Fct anonyme dans une autre fonction outer(x, y, function(x, y) x * y^2) ## une fonction est mise en argument d&#39;une autre fonction ## [,1] [,2] [,3] ## [1,] 16 25 36 ## [2,] 32 50 72 ## [3,] 48 75 108 11.10 Retourner un résultat Une fonction retourne le résultat de la dernière expression du corps de la fct. -&gt; donc il ne faut pas que la dernère expression soit une affectation (&lt;-), sinon on ne pourra pas affecter le résultat à un objet On peut retourner un résultat spécifique, à n’importe quel endroit de la fonction avec la fct return() Si le résultat que l’on veut retourner est codé par la dernière expression, return() est inutile. “return” se met plutot à la fin d’une fct, sauf cas exeptionel (if…), car la fct n’affiche plus les msg/stop si le return s’est effectué. Lorsqu’une fonction doit retourner plusieurs résultats, il est en général préférable d’avoir recours à une liste nommée. Retourner plsrs outputs : Outputs &lt;- list(objt1 = objt1, objt2 = objt2) return(Outputs) Si une fct retourne plsrs ouputs, elle doit toujours les retourner. S’il ne sont générés que sous condition, créer un objet vide du m^me nom lorsque la condition n’est pas respectée. 11.11 Fonctions de message et d’arrêt de fonction message() = message diagnostique (juste informatif) warning() = message d’erreur (problème non rédhibitoire (ex: syntax)) stop() = message d’erreur + arrêt du code (rédhibitoire) “stop” est une fonction d’erreur, si c’est juste une question de prérequis, il faut utiliser “if” pas “stop”. Un “stop” dans une fonction interne arrête également la fonction dans laquelle elle est inscrite. “try” : essaye la fonction interne sans stopper la fonction englobante. “catch” : capture le résultat du “try” quel qu’il soit. verbose : par défaut = TRUE dans R donc si on veut tjrs tout afficher il ne sert à rien de le mentionner Pour demander confirmation à l’utilisateur : readline(“pay attention to me!(press enter to continue)”) 11.12 Interaction avec l’utilisateur fun &lt;- function() { ANSWER &lt;- readline(&quot;Are you a satisfied R user? &quot;) ## question if (substr(ANSWER, 1, 1) == &quot;n&quot;) ## check the answer cat(&quot;This is impossible. YOU LIED!\\n&quot;) ## re-prompt else cat(&quot;I knew it.\\n&quot;) } if(interactive()) fun() 11.13 Iteration https://r4ds.had.co.nz/iteration.html itérer n fois : replicate(n, expr, simplify = F) (renvoie une liste) ou purrr::rerun(n, expr) ou purrr::map(1:n, ~ expr) ou lapply(seq_len(n), function(x) fun()) ## fun0 a function ## fun1 a a function to iterate fun0 with a n argument fun1 &lt;- function(n, x) replicate(n, fun0(x = x)) fun1(n, x) set.seed(1) fun0 &lt;- function(x) as.list(matrix(c(1, 1, 1, x + rnorm(1)), nrow = 2)) n &lt;- 1000 fun0(1) library(microbenchmark) mb &lt;- microbenchmark( repl = {replicate(n, fun0(1), simplify = FALSE)}, reru = {purrr::rerun(n, fun0(1))}, map = {purrr::map(1:n, ~fun0(1))}, lap = {lapply(seq_len(n), function(x) fun0(1))}, times = 1000L ) mb mb &lt;- microbenchmark( suit = {1:n}, rep = {rep(1, n)}, seq_len = {seq_len(n)}, seq_along = {seq_along (n)}, ## le + rapide c = {c(1:n)}, times = 1000L ) mb repeat() : répète à l’infini si on ne met pas une condition et un break dedans. Boucle for ou boucle while Encapsuler une boucle dans une fonction apply family (base) : apply(), lapply(), tapply(), etc map family (purrr) (+ rapides car écrite en C): map() (makes a list), map_lgl() (logical vector), map_int() (integer vector), map_dbl() (double vector), map_chr() (character vector). Les map ne produisent que des vecteurs, pas de matrice) Peuvent apliquer des fonctions ou des formules (https://r4ds.had.co.nz/iteration.html). Les boucles for ne sont plus lentes depuis de nombreuses années. Le principal avantage de l’utilisation de fonctions comme map() n’est pas la vitesse, mais la clarté : elles rendent votre code plus facile à écrire et à lire. Modif de l’output : transposer une liste (inverser la tructure) : purrr::transpose() 11.14 Parallelisation https://nceas.github.io/oss-lessons/parallel-computing-in-r/parallel-computing-in-r.html https://bookdown.org/rdpeng/rprogdatascience/parallel-computation.html Why : for time and memory 1 processor = multiple cores = multiple computations to be executed at the same time. R is sequential and uses 1 processor Plus simple de paralléliser des taches indépendantes, 1 par coeur. 1 tâche = 1 fct Packages : parallel, future, foreach, doParallel diffèrent selon les syst d’exploit on dirait Parallel functions : - detectCores() : détecte le nbr de coeur de la machine. - mclapply() : utiliser plsrs coeurs sur un ordinateur local (= parallelized version of lapply) (pas sous windows) - makeCluster() and clusterApply() : utiliser plusieurs processeurs sur des machines locales (et distantes) - clusterExport() : à distance Sous windows on ne peut pas paralléliser en local il faut donc un cluster : - créer un cluster : cl &lt;- makePSOCKcluster(nbr de copies de R à créer) (à défaut d’avoir des coeurs il crée plsrs copies de R) - créer l’envmt du cluster : clusterExport(cl, varlist = c(“var1”, “var2”), envir = environment()) - paralléliser : parLapply(cl, seq_along(iter), myfun) - arrêter le cluster : stopCluster(cl) https://stackoverflow.com/questions/17196261/understanding-the-differences-between-mclapply-and-parlapply-in-r library(parallel) cl &lt;- makePSOCKcluster(4) ## créer un cluster myfun &lt;- function(i) { Sys.sleep(1); i } ## the function parLapply(cl, 1:8, myfun) ## parallelization stopCluster(cl) ## stop the cluster Sur des boucles : - foreach sequential operator : %do% - doParallel parallelizable operator : %dopar% ## nonparallel for loop for (i in 1:3) { print(sqrt(i)) } ## nonparallel foreach loop library(foreach) system.time({ foreach (i=1:3, .combine=c) %do% { ## .combine=c si on veut unlist l&#39;output, .combine=rbind si on veut un df sqrt(i) } }) ## doParallel = foreach parallel adaptor for the &#39;parallel&#39; package library(doParallel) numCores &lt;- parallel::detectCores(logical = FALSE) ## FALSE to have the physical cores system.time({ registerDoParallel(numCores) foreach (i=1:3) %dopar% { sqrt(i) } }) When you’re done, clean up the cluster : stopImplicitCluster() 11.15 Choses à savoir Une fct a un environnement propre (ses var sont locales et ne vont pas dans l’envmt de travail): ainsi pas de conflit. Eviter donc d’utiliser des objets provenant de l’envmt de travail. Pour cela le mieux est de garder son environnement global tjrs vide (vider tt l’envrmt global : rm(list = ls())) On peut définir une fonction à l’intérieur (= fonction interne) d’une autre fonction. Cette fonction sera locale à la fonction dans laquelle elle est définie. 11.16 Débogage tips Lorsque Browse[1]&gt; s’affiche dans la console, on peut écrire des commandes utilisant l’environnement de la fonction en bug, et donc la travailler. Un booléen T/F ne marche pas si des NA existe Lorsqu’une fct ne retourne pas le résultat attendu, placer des commandes print à l’intérieur de la fct, afin de suivre les valeurs prises par les différentes variables. On peut même écrire print(1) après la 1ère ligne, print(2) après la 2eme, ainsi de suite pour savoir à quelle ligne se trouve l’erreur. Quand ce qui précède ne fonctionne pas, ne reste souvent plus qu’à exécuter manuellement la fonction : définir dans l’espace de travail tous les arguments de la fonction, puis exécuter le corps de la fonction ligne par ligne. La vérification du résultat de chaque ligne permet généralement de retrouver la ou les expressions qui causent problème. ou masquez avec le « ## » toutes les commandes que vous venez d’éditer ou rajouter, sauf la 1ere, Sauvez, et testez le fichier afin de voir si cette ligne est correcte. Si « source » fonctionne, enlevez le prochain dièse. N’oubliez pas de sauver et de « sourcer » à chaque test. 11.17 Où écrire ses fcts ? Dans un fichier .R indépendant nom de fichier = nom de la fonction 11.18 Comment les utiliser ? Enregistrer le code de la fct dans l’envmt : source(“nomfct/file.R”) 11.19 Plusieurs fonctions internes - passation d’infos ## Main : fonction englobante main &lt;- function(inventory){ inventory.volume &lt;- getvolume(inventory) rm(inventory) inventory.final &lt;- filtervolume(patate = inventory.volume) rm(inventory.volume) return(inventory.final) } ## Fonctions internes getvolume &lt;- function(inventory){ inventory &lt;- inventory %&gt;% mutate(v = 2*d) return(inventory) } filtervolume &lt;- function(patate){ poireau &lt;- patate %&gt;% filter(v &gt; 0) return(poireau) } ## test inventory &lt;- data.frame(id = 1:10, d = rnorm(10)) main(inventory) "],["package-creation.html", "Cours 12 Package creation 12.1 References 12.2 Les packages R nécessaires 12.3 Creation du package 12.4 Tips de codeur 12.5 Eviter les messages d’erreurs 12.6 Commandes 12.7 Importation de fonctions 12.8 Créer des classes pour ses objets en plus de ceux de base 12.9 Créer une “méthode générique” 12.10 tidyverse 12.11 Vignette 12.12 Site du package : Pkgdown 12.13 Des petits messages à l’utilisateur 12.14 C++ 12.15 Biblio 12.16 Where stock my data in my package 12.17 Charger ces data 12.18 Tests 12.19 Un package pour tous 12.20 Mettre le package sur CRAN 12.21 Debugger 12.22 Versioning 12.23 Renommer le package 12.24 Installer le package 12.25 Générer la citation du package", " Cours 12 Package creation 12.1 References The original bible : https://r-pkgs.org/index.html en francais : https://www.imo.universite-paris-saclay.fr/~goude/Materials/ProjetMLF/editer_package_R.html Eric Marcon’s cours : https://ericmarcon.github.io/Cours-travailleR/ 12.2 Les packages R nécessaires Télécharger des packages d’aide à l’organisation et structure, nécessaire à l’écriture d’un package : ## install.packages(c(&quot;usethis&quot;, &quot;roxygen2&quot;, &quot;devtools&quot;, &quot;testthat&quot;, &quot;covr&quot;, &quot;goodpractice&quot;)) ## ## library(usethis) #automatise la création des dossiers, vignette, site ## ## library(roxygen2) #permet d’automatiser la documentation obligatoire des packages ## ## library(devtools) #boîte à outils, permettant notamment de construire et tester les packages ## # roxygen2::roxygenise()#refresh de la documentation ## ## library(testthat) # Create test units ## ## library(covr) # Test coverage report() ## ## library(available) #vérifier la disponibilité du nom de votre package ## ## # available::available(&quot;LoggingLab&quot;) # TreeData ## ## library(goodpractice) # Bonnes pratiques dans la construction de package (functions and syntax to avoid, package structure, code complexity, code formatting) ## gp(system.file(package = &quot;Maria&quot;)) #trouve les mauvaises pratiques de notre package ## si on avait une ancienne version de withr pour rstan ## remove.packages(&quot;withr&quot;) ## install.packages(&quot;withr&quot;) 12.3 Creation du package New Project &gt; New Directory &gt; R package using devtools… Nom du package : pas d’espace, pas d’underscore, ne pas commencer par un chiffre et en minuscule Build &gt; Install and restart construit et charge le package dans R 12.4 Tips de codeur Mesurer le temps d’exécution d’un code : system.time ou microbenchmark (fct1,fct2) pour des codes trés courts. Ce sont les médianes des temps de calcul qu’il faut comparer. Détacher un package de l’environnement : unloadNamespace() Définitions “Charger/Attacher” un package : pkg::fct = pas attaché library(pkg) = attaché dans un cas comme dans l’autre, le package est chargé (load) : on l’utilise. Trouver les non ASCII characters : tools::showNonASCIIfile(“R/zzz.R”) les lignes doivent faire 80 charactères max 12.5 Eviter les messages d’erreurs Ne pas sauter de lignes dans “DESCRIPTION” file 12.6 Commandes Build &gt; Install and restart permet de tester des modifications de code check ou devtools::check() permet de vérifier son code (màj de la documentation (dossier “man”), tests sur le code, renvoie erreurs et avertissements) checker uniquement les exemples : devtools::run_examples() git branch -d main dans la console permet de supprimer la branche “main” de git Documentation-exporter une fonction : placer le curseur dans la fonction et appeler le menu “Code &gt; Insert Roxygen Skeleton” (ou CTRL + ALT + SHIFT + R): roxygen2 la déclarera dans “NAMESPACE” après un “check” raccourcir les lignes du squelette : ctrl + shift + / 12.6.1 Comprendre le Skeleton = sera la page d’aide de la fonction ! Roxygen tags : @include : mentionne des fichiers .R appelés dans le fichier @import : importer l’intégralité des fonctions du package (seulement si on utilise bcp de fcts du package (ex: ggplot2) @importFrom package fct : aller chercher une fonction dans un package (à privilégier) @param : y décrire le paramètre et citér sa classe @section : créer une nouvelle section @return décrire le résultat de la fonction @export déclare que la fonction est exportée : elle sera donc utilisable dans l’environnement de travail @examples : - Ne pas runner l’ex durant les tests : Pour un exemple qu’on ne veut pas encore “checké” Hyperliens : nom affiché Si on n’en a marre de se répéter : + Cross-link documentation files : @seealso and @family. Inherit (héritée) documentation from another topic : @inherit, @inheritParams, and @inheritSection. Document multiple functions in the same topic with @describeIn or @rdname. Créer une fct pour les écrire !! https://cran.r-project.org/web/packages/roxygen2/vignettes/rd.html (Evaluating arbitrary code) 12.6.2 R folfer Contiendra 1 ou plsrs fichiers .R contenant nos fonctions. 1 fichier peut contenir 1 fonction ou on peut y rassembler plsrs fonctions regroupables 12.6.3 nom-package.R file = page d’aide du package (=1er bloc) (visible avec ?nomdupackage) = commentaires pour roxygen2 = supplément de la vignette C’est aussi là qu’on renseigne les global variables La générer : usethis::use_package_doc() #&#39; TreeData-package #&#39; #&#39; Forest Inventories Harmonization &amp; Correction #&#39; #&#39; @name TreeData #&#39; @docType package #&#39; #&#39; @section TreeData functions: #&#39; RequiredFormat #&#39; #&#39; @keywords internal &quot;_PACKAGE&quot; ## usethis namespace: start ### quiets concerns of R CMD check &quot;no visible binding for global variables&quot; utils::globalVariables(c(&quot;.&quot;, &quot;A&quot;, &quot;B&quot;, &quot;C&quot;)) ## usethis namespace: end NULL 12.6.4 NAMESPACE file “gestion des noms des objets” = interaction du package avec le monde exterieur : importation d’autres fonctions/packages, exportation de nos fonctions. 12.6.5 DESCRIPTION file Depends: liste des packages d’origine de chaque générique Depends: R (&gt;= 2.10), ggplot2, graphics Les alinéas sont nécessaires Tout package utilisé (dépendances) doit être mentionné dans le fichier DESCRIPTION, section ‘Imports’ Attention : les dépendences appartenant à R core (ex: stats, parallel) doivent être de meme version munimum que celle de R demandée. 12.6.6 .Rbuildignore = fichiers dans le package pour le constructeur, mais qui ne seront pas chargés avec le package pour l’utilisateur. 12.7 Importation de fonctions le package d’appartenance de la fonction doit obligatoirement être déclaré : DESCRIPTION &lt; Imports: nom package, nom package Le package tydiverse ne doit pas être importé car trés changeant Import du pipe : usethis::use_pipe() Pour ne pas le faire à la main (préférable): usethis::use_package(“stats”) Importer la fonction dans nompackage.R : #’ @importFrom package fct dans le squelette de la fct (fichier.R) la fonction importée doit être trouvable dans l’environnement du package en création : la meilleure pratique est de qualifier systématiquement les fonctions d’autres packages dans le code avec la syntaxe package::fonction() (Sylvain dit que non) 12.8 Créer des classes pour ses objets en plus de ceux de base class(x) &lt;- “MyClass” ou class(y) &lt;- c(“MyClass”, class(y)) si on veut ajouter une classe aux classes de l’objet déjà existantes 12.9 Créer une “méthode générique” méthode générique = modèle de fonction, sans code, à décliner selon la classe d’objet à traiter (ex : “plot”). Une méthode générique est plus lente en calcul que ses fonctions dérivées qui sont spécialisées à une classe d’objet. meth_generique &lt;- function(x, ...) { UseMethod(&quot;meth_generique&quot;) } ## Fonction dérivée : meth_generique.class &lt;- function(x, ...) { return(x * 3L) #le suffixe L signifiant que 3 doit être compris comme un entier. } ##créer une fonction dérivée à partir d&#39;une fonction dérivée déjà existante print.multiple &lt;- function(x, ...) { print.default(x$y)#n&#39;afficher que le resultats y } Sa signature : ensemble de ses arguments Les fonctions dérivées de cette méthode devront obligatoirement avoir les mêmes arguments dans le même ordre et pourront seulement ajouter des arguments supplémentaires avant “…” (qui est obligatoire). 1er argument : “x”. Dépend de la classe de l’objet 12.10 tidyverse Tout package doit être compatible avec le tydiverse. pour permettre l’utilisation de pipelines, l’argument principal = le premier fcts qui transforment des données doivent accepter un dataframe ou un tibble comme premier argument et retourner un objet du même format les méthodes plot() doivent être doublées de méthodes autoplot() avec les mêmes arguments qui produisent le même graphique qu’avec ggplot2. autoplot() : permet de visualiser tt type d’objet, meilleur que ggplot2. aes() devient aes_() et ajouter un ~ devant les noms des variables. R CMD CHECK NOTE “no visible binding for global variable” : mettre @importFrom rlang .data 12.11 Vignette Création usethis::use_vignette(“nomdupackage”) Les packages utilisés par la vignette doivent apparaitre dans DESCRIPTION C’est un rmd donc ne pas oublier de kniter souvent Contenu : + library(monpackage) dans le premier chunk. + introduction à l’utilisation du package + chunk avec un exemple d’utilisation Compilation : Pour compiler la vignette (Build ne le fait pas) (et la voir dans la page d’aide du package): Pour mettre une copie de la vignette dans /doc (durant le dvp) : devtools::build_vignettes() On peut détruire ce qui est dans doc/ après usage. Le dossier est déclaré dans .Rbuildignore et .gitignore. Push sur Github puis devtools::install_github(“DeveloperName/PackageName”, build_vignettes = TRUE) Cette methode (installer le package à partir de sa source) le permet aussi, mais plus triviale : https://www.r-bloggers.com/2020/05/how-to-add-a-vignette-to-a-package-in-rstudio/ Pour que le check ne construise pas la vignette : –no-build-vignettes dans options &gt; check et build pckg Si le build renvoie une erreur relative à qpdf : il faut installer les Rtools et au bon endroit (voir 1.1.2 Rtools TravailleR d’Eric Marcon) 12.12 Site du package : Pkgdown https://pkgdown.r-lib.org/articles/pkgdown.html ! le dépot doit être public ! Création site du package (dossier “docs”): usethis::use_pkgdown() puis pkgdown::build_site() Use GitHub actions to automatically build and publish the site every time you make a change usethis::use_pkgdown_github_pages() Configures a GitHub Action to automatically build the pkgdown site and deploy it via GitHub Pages : usethis::use_github_action(“pkgdown”) Home page : index.md or README.md Reference : liens vers les pages d’aide de toutes les fcts du package. On peut les organiser voir le lien. Articles : vignettes News : NEWS.md Customise your site: https://pkgdown.r-lib.org/articles/customise.html 12.13 Des petits messages à l’utilisateur Afficher des messages informatifs : cat() ex : cat(“multiplied by”, object$times, “is:”) donne “multiplied by 2 is:” 12.14 C++ un C++ file dans dossier “src” un .gitignore dans ce même dossier, dans lequel on met : “# C binaries src/.o src/.so src/*.dll” 12.15 Biblio Les réf biblio (sauf celles des .rmd (vignette, site) sont gérées automatiquement avec Rdpack et roxygen2 De notre zotero/mendeley vers : REFERENCES.bib dans le dossier inst Ajouter dans le fichier DESCRIPTION : RdMacros: Rdpack Imports: Rdpack Comment citer : citation(packagename) Biblio de la vignette : + créer un fichier bib + le déclarer dans l’entête + citer avec @citation. On peut éviter de multiplier les fichiers bib en utilisant celui de RdPack qui est inst/REFERENCES.bib : dans la vignette, tu déclares le chemin relatif : bibliography: ../inst/REFERENCES.bib 12.16 Where stock my data in my package 12.16.1 Testing data: Just for me : in inst/extdata (‘inst’ pour ‘installed’) : external data (private) (en csv) -&gt; no need to document For the user (and me) : in “data” : internal data (= deliver with the package) (public) -&gt; need to document 12.16.2 Default data: Dataset : in “data” : internal data (= deliver with the package) (public) -&gt; need to document Valeurs par default d’arguments de fct : Fct d’arguments : si on veut passer des valeurs par défaut dans une fct, on peut les proposer en arguments de celle-ci. S’il y en a bcp, on peut créer une autre fct qui aura pour arguments ces valeurs par défaut et qui créé une liste de celles-ci. Cette dernière fct sera entrée comme argument de la 1ère. Ainsi n’importe quelle valeur peut être modifiée sans avoir à tout réécrire. fun1(A, B, arg = fun2(arg10 = FALSE)) Liste dans data : on peut aussi juste créer la liste et en faire un data que l’utilisateur loadera, modifira, et injectera dans la fct en argument, mais ça lui demande donc du travail préliminaire. “Global options” in zzz file 12.16.2.1 “Global options” Where write options: in zzz file (in R folder), as a named list or vector (eg. pars &lt;- list(track_size = 2, method = “EFI”). Then you called pars$method.). Options = an object (here a list/vector) zzz file : on y met généralement les actions devant se réaliser au chargement du package. (https://cran.r-project.org/web/packages/GlobalOptions/vignettes/GlobalOptions.html#session_info) (https://github.com/mojaveazure/seurat-disk/blob/master/R/zzz.R) Inconvénients des options : on ne peut pas appliquer de apply sur différentes valeurs choisies d’une même option. Documenter les “options” du package : dans un fichier .R dons le dossier R (regarder ?rstan_options pour inspiration) Modification des options par l’utilisateur : options() http://www.endmemo.com/r/options.php If you modify global options() or graphics par(), save the old values and reset when you’re done: old &lt;- options(optionsname = defaultvalue) save the old values on.exit(options(old), add = TRUE) reset when you’re done To access the value of a single option, one should use, e.g., getOption(“width”) rather than options(“width”) which is a list of length one. 12.16.3 Exported data (in data/) accessible à l’utilisateur ! usethis::use_data(data1, data2) : crée un fichier (.rda) pour chaque jeu de données/variable, dans le dossier data pas conseillé de prendre un autre format de fichier, celui-ci est pertinent (rapide et léger). DESCRIPTION file : LazyData: true -&gt; data dispo dès le chargement du package, ne chargeront qu’au besoin. comprésser un fichier : bzip2, gzip ou xz si le fichier data est une version transformée d’une base de donnée, il est conseillé de mettre le code de transformation dans data-raw/ grace à : usethis::use_data_raw(“nom du data”) 12.16.4 Documenter ces données exportées Où : dossier ‘R’ nommé ‘data.R’ roxygen squeleton : ##&#39; Data title ##&#39; ##&#39; Data description ##&#39; ##&#39; @format A data frame with X rows and Z variables: ##&#39; \\describe{ ##&#39; \\item{var1}{description, in units} ##&#39; \\item{var2}{description, in units} ##&#39; ... ##&#39; } ##&#39; @source \\url{} commande d&#39;acquisition des données &quot;name&quot; 12.16.5 Internal data for a function (in R/sysdata.rda) Pour : stocker une base de données analysée/pré-calculée, dont a besoin une fonction. non-accessible à l’utilisateur ! -&gt; pas à être documenté mise dans R/sysdata.rda grace à usethis::use_data(, internal = TRUE) si le fichier data est une version transformée d’une base de donnée, il est conseillé de mettre le code de transformation dans data-raw/ grace à : usethis::use_data_raw() 12.17 Charger ces data Quand : pour les exemples et les tests, pas dans les fonctions ! Les fonctions ne manipulent que leurs propres objets (en 1er lieu leurs arguments). (Le mieux c’est de garder son environnement global vide lors de la création de la fonction.) system.file(“dossier”, “fichier”, package = “nompackage”) : donne le chemin vers un fichier d’un package, pour tout système d’exploitation. load() : pour charcher les .rda. Ex : load(system.file(“extdata”, “BrokenParacou6_2016.rda”, package = “Maria”)) read_csv : pour charcher les csv data(nomdufichier) : charge le fichier s’il est dans le dossier “data” du package 12.18 Tests Créer un dossier “tests” : usethis::use_testthat() écrire des tests à nos fonctions dans tests/testthat : usethis::use_test(name = “nomdelafct”) The test name should complete the sentence “Test that …”. ## test_that(&quot;Math works&quot;, { ## expect_equal(1 + 1, 2) ## expect_equal(1 + 2, 3) ## expect_equal(1 + 3, 4) ## }) lancer tous les tests : devtools::test() (Ctrl + Shift + T) Each test is run in its own environment and is self-contained. chaque test s’applique sur les outputs de la fct testée, pas sur les objets internes dans les test, ne charger la function qu’1 fois si possible pour limiter le temps de calcul (limité sur CRAN) Ne pas afficher les messages renvoyées par les fcts testées dans les tests : suppressMessages(fun()) package “teststat” : vérification que la fonction fonctionne et renvoie les valeurs qu’on veut package “covr” (juste copier report() dans la console) : qui dit quelle proportion du code est sous unités de tests (couverture) Devtools (https://testthat.r-lib.org/reference/index.html): expect_equal() is equal within small numerical tolerance? expect_identical() is exactly equal? expect_match() matches specified string or regular expect_message() displays specified message? expect_warning() displays specified warning? expect_error() throws specified error? expect_type() output inherits from certain class? expect_false() returns FALSE? expect_true() returns TRUE? logical-expectations() : Does code return TRUE or FALSE? expect_null() : Does code return NULL? expect_length : code return a vector with the specified length? equality-expectations() : code return the expected value? expect_vector() : Does code return a vector with the expected size and/or prototype? expect_named() : Does code return a vector with (given) names? comparison-expectations() : Does code return a number greater/less than the expected value? expect_setequal() : Does code return a vector containing the expected values? expect_output() : Does code print output to the console? try_again() : Try evaluating an expressing multiple times until it succeeds. make_expectation() : Make an equality test. test_examples() : Test package examples these functions have two arguments: the 1st is the actual result, the 2nd is what you expect. 12.19 Un package pour tous Pour tout système d’exploitation : mentionnés dans le yaml de githubactions : il fait les tests pour chacun d’eux 12.20 Mettre le package sur CRAN Version number : changer le numéro en version (plus en dévelopement = sans le 9000) (major.minor.patch) (1.0.0) Test environments : tous les tests doivent êtres réussis sur min 2 syst d’exploitation 0 notes/warning/error Backward compatibility : pas important pour la première version mais important pour la suite si le package évolue Submission : je déconseille d’utiliser devtools::release() mais plutôt de le faire à la main pour bien contrôler les étapes comments.md : très important Dépendances : toutes les dépendances hors base doivent être inclue, y compris des packages core comme stat ou utils (à discuter). Prepare for next version : je pense que c’est super important et que la plupart des gens ne le font pas. En gros une fois que CRAN a dit oui tu es contente et tu vas vouloir t’arrêter là. Sauf qu’un package est souvent destiné à évoluer et cette petite étape te permettra juste de réattaquer facilement, donc je trouve ça vitale. 12.20.1 Les tests Githubactions : pour un contrôle standard :usethis::use_github_action_check_standard() -&gt; R-CMD-check.yaml creation https://youtu.be/K4x-uqLl_m4 Si les Github Actions Windows ne fctnent pas (ne trouve pas les fcts du package), alors que ça marche sur les autres OS, dans le R-CMD-check.yaml: # https://github.com/privefl/minipkg/commit/50224bcf5f1fd4e30a8c15d2a10534fb247fef4b - name: Install dependencies run: Rscript -e &quot;install.packages(&#39;devtools&#39;)&quot; -e &quot;devtools::install(dependencies = TRUE)&quot; Codecov : test-coverage.yaml (https://github.com/r-lib/actions/tree/master/examples#test-coverage-workflow) (créer un “secret” pour le token sur github si le dépot est privé) Il faut créer un compte codecov 12.21 Debugger tapper ligne par ligne dans la console la partie qui coince Lorsque Browse[1]&gt; s’affiche dans la console, on peut écrire des commandes utilisant l’environnement de la fonction en bug, et donc la travailler. 12.22 Versioning https://r-pkgs.org/release.html#release-version major.minor.patch.9000 .9000 only for dvlmpt version major, nimor, patch for released version il peut y avoir des versions de dvlp entre released versions For development version: 9000 +1 / commit for example. You can choose your unit For released version: patch : just debuging, no addings minor : debuging, addings, with backward compatibility (same functions and arguments names) major : substantive changes, not backward compatible, affect many users 12.23 Renommer le package https://docs.github.com/en/repositories/creating-and-managing-repositories/renaming-a-repository + Renommer le dépôt Github puis + $ git remote set-url origin new_url in the shell + ctrl + shift + F remplacer l’ancien nom par le nouveau dans tous le package 12.24 Installer le package Dépot public : devtools::install_github(&quot;DeveloperName/PackageName&quot;, build_vignettes = TRUE) Dépot privé : Create an access token in: https://github.com/settings/tokens devtools::install_github(&quot;user/repo&quot; ,ref=&quot;master&quot; ,auth_token = &quot;tokenstring&quot; # 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 ) 12.25 Générer la citation du package mettre un onglet Date dans le fichier DESCRIPTION, y écrire une date dans le format yyyy-mm-dd et runer citation(“nom du package”) "],["shiny-cours.html", "Cours 13 Shiny cours 13.1 Packages 13.2 Tips codeur 13.3 Shiny: 13.4 Structurer l’appli 13.5 Créer l’interface 13.6 Gérer les intéractions 13.7 Enrichir l’appli 13.8 Autres packages 13.9 Mise en ligne et partage de l’appli 13.10 Module 13.11 Autres sources cours", " Cours 13 Shiny cours 13.1 Packages library(shiny) # Web Application Framework for R library(bslib) # aesthetic, thème et feuilles de style ## bslib::bootswatch_themes() # pour voir ts les thèmes library(shinydashboard) ## library(bs4Dash) # dashboard aussi. restart R session si on passe d&#39;un pkg à l&#39;autre (dont mode jour/nuit mais mal fait) library(shinyjs) # Improve the User Experience library(dplyr) library(ggplot2) library(thematic) # Aesthetic, Unified and Automatic &#39;Theming&#39; of &#39;ggplot2&#39;, &#39;lattice&#39;, and &#39;base&#39; R Graphics library(DT) # Interactive table library(leaflet) # Interactive Web Maps library(plotly) # Interactive Web Graphics 13.2 Tips codeur à la fin d’une grosse parenthèse/accolade préciser de quoi c’est la fin #### titre partie #### ou tirets ou égales pour faire des parties déroulantes dans le code 13.3 Shiny: Package gratuit dvp par Rstudio donne à l’utilisateur une page web à consulter Ne supporte que l’encodage UTF-8 ce qu’on peut y mettre : - curseurs - cases à cocher - graphiques - cartes intéractives (changer le fond) - changer la langue - process automatique -&gt; vidéo - arbres décisionnaires R ne fait qu’1 tache à la fois donc Shiny aussi, mais il existe des moyens de palier à ça. R -&gt; Shiny -&gt; Bootstrap -&gt; HTML/CSS/JavaScript -&gt; Navigateurs internets structurer l’appli créer l’interface gérer les intéractions enrichir l’appli mise en ligne et partage de l’appli 13.4 Structurer l’appli créer un dossier ac le nom de l’appli 2 fichiers : ui.R et server.R enregistrés en UTF-8 ui.R : dont fct fluidPage() (mise en forme de l’interface) server.R : dont fct server &lt;- function(input, output, session) global.R (optionnel, même dossier) : chargement de variables dans envrment global de l’utilisateur Il est possible de mettre ces 3 codes dans un même fichier. Lancement de l’appli : bouton “Run App” ou shiny::runApp (“dossierdes2fichiers”) Appuyer sur STOP qd fini 13.5 Créer l’interface ui.R et sa fct créent l’interface graphique Le code R dans ui est converti en HTML (on peut aussi mettre du HTML dans ui (HTML())) sous-dossier www avec (non aacessibles sous code, uniqueùment sous ap): - image.png - style.css - script.js Formater du texte (fcts inspirée du HTML) à mettre dans fluidPage(): p() : paragraphe h1~h6() : 1er niv d’en-tête à 6ème niv *a(href =, target = “_blank)* : lien hypertexte, target = “_blank permet d’ouvrir dans un nouvel onglet br() : retour à la ligne code() : Police code strong() : gras em() : italique img(src = image dans www) : insérer une image , à la fin de chaque ligne dans ces fonction (sépare les args) clic droit sur la page web pour en voir le code de mise ne forme en html. 13.5.1 Mise en page Page titlePanel (titre) Layout side bar panel main panel tapPanel1,2,3 Mettre des onglets : tabsetPanel() : conteneur dedans 1er onglet : tabpanel(), 2ème onglet : tabpanel(), etc Page barre latérale et panneau principal, 1/3-2/3 : sidebarLayout() (conteneur) 13.5.2 INPUTS &amp; OUPUTS Répertoriés ici: https://shiny.rstudio.com/gallery/widget-gallery.html Dans ui : INPUT + actionButton : bouton + actionLink : bouton + checkboxInput : entrée numérique + checkboxGroupInput : groupes de cases à cocher + dateInput : date avec propositions + dateRangeInput : période OUTPUT + plotOutput : graphique + imageOutput : image + tableOutput : print tableau + dataTable : tableau optimisé (interactif: affichage et recherche) + text + verbatim : format console R + html/uiOutput : ui dynamique (faire apparaitre des choses au départ caché) 13.6 Gérer les intéractions Sur ui: un identifiant (inputId =) unique par input/output et parlant label, choices seront visibles sur l’app selected : valeur selectionnée par dédaut Sur server.R : output\\(idouput &lt;- renderText(){input\\)idinput} c’est l’objet calulé à la dernière ligne qui est utilisé pour mettre à jour l’outpout 1 fct/output même pour un même input on peut mettre un print avant la der ligne de code pour afficher le rslt dans console un input répétitif peut être mis sous forme de fct et mis soit dans servers soit dans global. Réaction réactive : la fct reactive permet de ne pas recalculer même input à chaque output (comme un cache) (diapo 46) Chaine de réactivité : Reactive value -&gt; Reactive expression -&gt; Rendu &amp; output ou Observer input = reactive value + élmt graphique (cases, surseur etc) Reactive value avec reactiveValues(result = NULL) (voir server de calculatrice) Reactive expression = calcul lourd, extract données, mise en cache pour plsrs render/oberver. Rendu &amp; output = mise à j d’un output avec un nouvel objet. Observer = gestion fine de l’interface : gestion d’evnment (click bouton), gestion de proxy. Une expression réactive peut en observer une autre expression réactive (propagation) Fonctions : reactiveValues reactive eventReactive : réagit à un évenemnt mis en 1er argument observe observeEvent isolate pour ne pas appliquer un code sans l’activation d’un code précédent (voir server calculatrice). invalidateLater : ré-exécution d’un observateur/render/expr rel après un certain laps de temps debounce/throttle 13.7 Enrichir l’appli 13.7.1 Leaflet cartographie (représentation spatiale) dynamique Utilise le pipe choisir le fond de carte voir code diapo ~devant les vars de data Définir le zoom initial voir code diapo ajouter des points spécifiques (markers) voir code diapo personaliser les points (description des markers) voir code diapo Ajouter des formes rayon en mètres voir code diapo Ajouter une légende voir code diapo Ajouter une échelle et la possibilité de faire des mesures voir code diapo Après un render pour initialiser, un proxy, encapsulé dans un observe, pour ne pas recalculer le fond de carte à chaque modif. L’objet à mettre à a préalablement été construit dans un render Des proxy existent pour leaflet, DT, plotly 13.7.2 Charger/enregistrer des fichiers Il faut mettre une limite max de gigas pour protéger le serveur. 13.7.2.1 Charger Fichiers fournis par l’utilisateur : input Dans ui : fileInput(inputId = “fiMyFiles”, multiple = TRUE,…) Dans server : diapo p54 package shinyFiles pour fichiers lourds 13.7.2.2 Enregistrer Fichiers transmis à l’utilisateur : output Dans ui : downloadButton(outputId = “myReport”,…) Dans server : diapo p54 13.7.3 Shinydashboard permet de personnalisr la partie ui (rien ne change dans la partie server) Barre de navigation à gauche et une page principale pour les figures 3 parties : header, sidebar, body Dans le body, différentes boites (box) pour les différentes sorties On peut ajouter des onglets dans la sidebar, liée à la partie body Menu avec messages, notif, taches en haut à droite InfoBox, ValueBox (valeurs numériques d’intérets) Personnalisation box (rétractable, ) la hauteur s’adapte au contenu 13.8 Autres packages shinyjs : visibilité d’élmt, activité d’élmt, attributs d’éléments (couleur selon la class), code javascript shinyjs::hidden : cacher un bouton shinyWidgets : bouton switch, sliderText shinyalert : création de boite de messages personnalisée shinyhelper : ajouter de l’aide à une appli (description) plotly : graphiques ggplot2 intéractifs shinysccloaders : spinner (truc qui tourne) pendant le calcul shinyFeeback ou shinyvalidate : avertissement, erreur sur les valeurs saisies Tableau éditable : excelR, DataEditR, shiny-matrix Crosstalk : sélection commune et synchronysée entre plsrs outputs (pour plotly, leaflet, DT) ShinyMobile : plus adaptée à une interface téléphone, ressemble plus à une appli 13.9 Mise en ligne et partage de l’appli 13.9.1 En local : c’est mieux, plus rapide car outils de calcul et on y est seul à travers un package, on peut lancer son appli avec le Addins dans Rstudio ou juste dépot pour l’appli sur github Application Windows sans ouvrir Rstudio, avec un R-portable (lourd) 13.9.2 A distance plsrs utilisateurs sur 1 serveur R/Shiny ShinyProxy : 1 R pour chaque utilisateur Hébergement dédié (Shinyapps.io) : offre gratuite avec des limitations 13.10 Module -&gt; Répéter des outputs pour différents onglets dans ui : création des onglets avec des données spécifiques dans server : callModule() Code du module dans dossier R (pas de sous-dossier), qu’il faudra sourcer fct avec code pour ui : création d’ID unique avec shiny::ns() fct avec code pour server 13.11 Autres sources cours mastering shiny "],["stats-à-ne-plus-chercher.html", "Cours 14 Stats à ne plus chercher 14.1 Corrélations 14.2 Evaluer la performance d’une prédiction 14.3 Processus gaussiens", " Cours 14 Stats à ne plus chercher 14.1 Corrélations Une base de traits (quantitatifs) à tester : baseforcor &lt;- rootsmassMarco %&gt;% select(-var quali) pas besoin de tester la normalité si n&gt;30. CorMatrix1 &lt;- round(cor(baseforcor, use = “pairwise.complete.obs”), digits = 2) # matrice de corrélation, avec 2 décimales pour avoir les p-values : CorMatrixS &lt;- rcorr(as.matrix(baseforcor)) CorMatrix &lt;- CorMatrixS\\(r Pval_corr &lt;- CorMatrixS\\)P Plot de la matrice de corrélation : http://www.sthda.com/french/wiki/visualiser-une-matrice-de-correlation-par-un-correlogramme corrplot(CorMatrix, method=“circle”, type=“lower”, col=brewer.pal(n=8, name=“PuOr”), tl.col=“black”, tl.srt=45, p.mat = Pval_corr, sig.level = 0.05) #avec une croix pour les p-value &gt; 0.05. ##Inférer des données = Remplacer les NA selon les autres variables MICEinf &lt;- mice(data, maxit=100) 100 itérations, methodes par défault Visualiser les valeurs produites MICEinf\\(imp\\)varinf Mettre ces valeurs inférées dans ma base Data_completed &lt;- complete(MICEinf,5) ici j’ai pris la 5eme (m) estimation ##Standardizer (centrer-réduire) as.vector(scale()) 14.2 Evaluer la performance d’une prédiction 14.2.1 Validation croisée (rééchantillonage) = séparer données en jeux d’entraînement et de test : caret::createDataPartition() 14.3 Processus gaussiens généraliser la procédure à une quantité infinie de dimensions kernlab::gausspr() -&gt; écart-type des prédictions, donnant une appréciation de la précision du modèle "],["introduction-à-stan.html", "Cours 15 Introduction à Stan 15.1 Pourquoi les stats bayesiennes ? 15.2 Stan program :", " Cours 15 Introduction à Stan library(readr) library(tidyverse) library(rstan) rstan_options(auto_write = TRUE) #option pour ne pas recompiler à chaque fois !!! gain de temps options(mc.cores = parallel::detectCores()) #option pour ajouter des coeurs au calcul library(bayesplot) #visualiser la chaine de Markov library(shinystan) #for interactive stan output visualization library(rstanarm) #for Bayesian automatic regression modelling using stan library(brms) #Bayesian generalized multivariate non-linear multilevel models using stan 15.1 Pourquoi les stats bayesiennes ? on peut exprimer nos croyances/expertises sur les paramètres (prior) prend en compte l’incertitude proprement permet de prendre tout niveau de complexité de modele Theoreme de Bayes * Prior : proba des paramètres apriori * Vraissemblance : proba des données sachant les paramètres * Posterior : distribution des paramètres sachant les données Stan = un language : - entre crochet - un point-virgule à la fin de chaque ligne - // pour commencer un commentaire - &lt;lower=0&gt; : pour borner la variable 15.2 Stan program : Ôuvrir un fichier stan. 3 blocks de commande : data block on déclare : - la taille du jeu de donnée - les differentes variables parameters block On déclare le nom des paramètres et leurs bornes si on le souhaite model block - on déclare le prior (loi que suit le paramètre) (permet d’augmenter la vitesse d’analyse) - sinon prior non-informatif - écriture du modèle (vraissemenblance) Les priors doivent être définis sous sens biologique/écologique GLOPNET &lt;- read_csv(&quot;GLOPNET.csv&quot;, skip=10) LES &lt;- GLOPNET %&gt;% filter(BIOME==&quot;TROP_RF&quot;, GF == &quot;T&quot;) %&gt;% select(Dataset, Species, &quot;log LL&quot;, &quot;log LMA&quot;) %&gt;% na.omit() #le bayesien ne supporte pas les NA LES %&gt;% ggplot(aes(`log LMA`, `log LL`, col=Dataset)) + geom_point() + xlab(&quot;Logarithm of Leaf Mass per Area (LMA)&quot;) + ylab(&quot;Logarythm of Leaf Lifespan (LL)&quot;) Modèle proposé : _log LL ~ N(alpha + beta *log LMA, sigma^2)_ -&gt; régression linéaire à mettre dans un fichier stan data &lt;- list( N = dim(LES) [1], #les noms des var doivent etre les memes que dans le fichier stan logLMA = LES$&quot;log LMA&quot;, logLL = LES$&quot;log LL&quot; ) fit1 &lt;- stan(&quot;stan.stan&quot;, data = data) #LET&#39;S GOOOO! Données injectées, compilation lancée ! Nombre de chaine par défaut mais on peut choisir, 4 c’est le minimum pour interpréter les graphes. thin = période d’amaigrissement = pas de l’itération warmup = periode de chauffe : petite balade aléatoire lp_ = log de la vraisemblance n_eff = nbr d’itérations effectives : qui sont relevantes Rhat doit être égal à 1 (ou 1.1): ça veut dire que l’estimation des paramètres a réussi à converger Ici les chaînes n’ont pas réusi à converger, et ce sont perdues (tres peu de chaînes effectives). mcmc_trace(as.array(fit1), #as.array = comme vecteurs facet_args=list(labeller=label_parsed), #pour mettre en lettre greques np = nuts_params(fit1)) # np pour afficher la divergeance MCMC : diagnostic des chaines PPC : comparaison de modèles Il faut une exploration indépendante des paramètres pour trouver le point où ça cohabite = maximum de vraissemblance (voir dessin carnet) #les paramètres doivent être indépendants et former une patate à leur valeur correspondant aux données. mcmc_pairs(as.array(fit1)) On voit que alpha et lp_ sont liés par une relation. On voit sur les graphes des chaines, que alpha veut aller dans le négatif mais ne peut pas car défini sur R+ (loi gamma) Logique biologique : alpha doit être égal à 0 quand LMA est égal à 0 puisque s’il n’y a pas de masse il n’y pas de feuille dont pas de duree de vie !!! Donc on vire alpha du modèle. Nouveau modele : _log LL ~ N( beta *log LMA, sigma^2)_ A mettre dans un fichier stan On peut faire une copie de l’ancien fichier : file &gt; coche le stan file &gt; more &gt; copy fit2 &lt;- stan(&quot;LLLMA.stan&quot;, data = data) mcmc_trace(as.array(fit2), #as.array : comme vecteurs facet_args=list(labeller=label_parsed), np = nuts_params(fit2))#pour mettre en lettre greques mcmc_pairs(as.array(fit2)) Ca fait des belles patates donc c’est bon !!!! Et de beaux histos ! On veut mtn connaitre les distributions des paramètres à posteriori: on veux des paramètres : - différents de 0 (pour une relation entre var expli et var réponse) - et un sigma petit (pour un bon fit) mcmc_areas(as.array(fit2), prob=0.95, pars = c(&quot;beta&quot;, &quot;sigma&quot;)) # pars pour n&#39;afficher que les paramètres que je veux, pas la vraissemblance Posteriors sont normaux et significatifs. mcmc_intervals(as.array(fit2), prob=0.95, pars = c(&quot;beta&quot;, &quot;sigma&quot;)) #vu du dessus launch_shinystan(fit2) Conclusion : - se renseigner sur les formes de lois, de modèle - la définition des lois - centrer-réduire les variables pour faire converger plus vite (meme echelle) - borner les paramètres si possible "],["i-am-a-modeler.html", "Cours 16 I am a modeler 16.1 La modélisation 16.2 Modèle linéaire simple 16.3 Lois de probabilité de la fonction de réponse 16.4 GLM (modèles linéaires généralisés) 16.5 Modèle mixte 16.6 Créer nos prédicteurs selon l’effet que l’on veut tester 16.7 tests 16.8 Estimations des paramètres 16.9 Variable réponse qualitatite", " Cours 16 I am a modeler 16.1 La modélisation On récolte n observations qui sont le résultats de n expériences aléatoires indépendantes. Modélisation : on suppose que les n valeurs sont des réalisations de n variables aléatoires indépendantes et de même loi. Estimation : chercher dans le modèle une loi qui soit le plus proche possible de la loi de notre var réponse = chercher un estimateur de theta0. “Validation” de modèle : on revient en arrière et on tente de vérifier si l’hypothèse de l’étape 2 est raisonnable ((normalité, linéarité, analyse des résidus, test d’adéquation, etc…) Modèle non-paramétrique : univers de dimension infinie Modèle paramétrique : univers de dimension finie 16.2 Modèle linéaire simple Variables quantitatives -&gt; régression Variables qualitatives -&gt; ANOVA (analyse de la variance) Variables mixtes -&gt; ANCOVA (analyse de la covariance) 16.3 Lois de probabilité de la fonction de réponse loi de probabilité = - sa fct de répartition - sa densité Différentes lois : - Variable réponse continue : Normale ou Gamma - Réponse binaire (succès-échecs, présence-absence) : Bernoulli (1 seul tirage), binomiale (plsrs tirages(nbr de succés, proportion)) Comptages (nbr entiers) : Poisson, négative binomiale, Geométrique Durée de survie : Exponentielle Choix (l’adéquation du modèle aux données) : -la déviance normalisée (scaled deviance) : retenir celle qui minimise la déviance D -la statistique du khi-deux de Pearson - AIC, BIC, régression lasso Lorsque le modèle étudié est exact, la déviance normalisée D* ou le khi-deux de Pearson, suit approximativement une loi du khi-deux àn-K degrés de liberté. 16.4 GLM (modèles linéaires généralisés) Dans quel cas ? quand la variable réponse et les variables explicatives ne sont pas définis sur le même univers (intervalle de valeurs). GLM : - Modèle linéaire gaussien : Gaussienne - Régression logistique : Bernouilli (binaire), variable réponse catégorielle, ordinale ou polytomique (modalités) - Log-linéaire : Poisson Une fonction de lien spécifique (= fonction de lien canonique) permet de relier l’espérance μ au paramètre naturel theta (ou canonique) de la loi. En d’autres mots, lier l’espérance de la variable réponse (μ) au prédicteur linéaire construit à partir des variables explicatives. Fcts de lien naturel: - Pour la loi Normale : theta = μ (link=’identity’) - Pour la loi Poisson : theta = log(μ) (link=’log’) - Pour la loi Bernouilli : theta = logit(μ) = log(μ/1-μ) (= logarithme du rapport des chances) (link=’logit’) - Pour la loi Gamma : theta = 1/μ (link=’inverse’) Fcts de liens : - Identité - Logit : est adaptée au cas où μ est comprise entre 0 et1 (par exemple la probabilitéde succès dans une loi binomiale). Approbriée quand les proportions de 0 et de 1 sont équilibrées - Probit : est l’inverse de la fonction de répartition de la loi normale centrée réduite. Approbriée quand les proportions de 0 et de 1 sont équilibrées. - clog–log : Approbriée quand les proportions de 0 et de 1 sont trés déséquilibrées (Hardin and Hilbe (2007)) - Puissance - Logarithme - Gompit( complémentaire log log) [0;1] : logit, probit, clog–log, and log–log Sauf cas (très) particulier, le lien n’est jamais “parfait”. La fonction de lien est inversible. Choix de la fct de lien : le choix de la fonction de lien est libre. Néanmoins choisir la fonction de lien naturel permet d’assurer la convergence de l’algorithme d’estimation utilisé classiquement (algorithme de Newton-Raphson) vers le maximum de vraisemblance. 16.5 Modèle mixte = modèle contenant des effets fixes et des effets aléatoires. Effets fixes = effet d’une variable mesurée, avec des niveaux/groupes qui sont délibérément arrangés par l’expérimentateur, donc bien définie et controlée, sur une var réponse. Effets aléatoires = effet sur la structure de l’échantillon, dont les niveaux sont possibles. Dans l’étude de ce type d’effet on ne s’intéresse pas à l’effet qu’a chacun des groupes mais à la variabilité totale qu’ils apportent à la var réponse. 16.6 Créer nos prédicteurs selon l’effet que l’on veut tester interaction entre 2 variables : X3= X1*X2 (multiplication de var) effet non linéaire : X4 = X1^2 (exposant sur une variable) 16.7 tests Le test t permet de tester l’hypothèse H0 pour chaque variable. Le test de Fisher permet de tester plusieurs paramètres simultanément. Le test de Fisher a plus de sens dans le cas d’une ANOVA car il considère la variable explicative dans son ensemble et non modalité par modalité. 16.8 Estimations des paramètres Par minimisation des moindres carrés ou maximum de vraissemblance Résidus (epsilon) = Y - estimation d’Y (y chapeau) 16.9 Variable réponse qualitatite Chercher à expliquer Y par X revient à chercher de l’information sur la loi de probabilité de Y sachant X. Si on peut, rendre la variable binaire (0,1) -&gt; Bernoulli -&gt; Régression logistique "],["bayesian-stats-cours.html", "Cours 17 Bayesian stats cours 17.1 Grid approximation (to define posterior) :", " Cours 17 Bayesian stats cours design the model (data story) condition on the data (update the model) evaluate the model (critique) ex : 9 times dta : W (water) or L (land) p = proba de W proba de L = 1-p prior : information before the data (p in [0;1]) posterior : update info of each value of p conditional on data chaque postérior est le prior du prochain posterior plus on a de données plus il est aisé d’avoir un résulat précis Define generative relations between the variables W, L, W p * (1-p) *p = p2(1-p)1 : relative number to see W Vraissemblance : 17.1 Grid approximation (to define posterior) : posterior proba = standardizez product of proba of the data and prior proba standardisé : add up all the products and divide by this sum grid approximation uses finite grid of parameter values instead of continuous space too expensive with more yhan a few parameters Sampling from the posterior Intervals : how much mass Percentile intervals (PI): equal area in each tail Hightest posterior density intervals (HPDI) : narrowest interval containing mass Mean nearly always more sensible than the mode Model : "],["bayesian-and-stan-langage.html", "Cours 18 Bayesian and Stan langage 18.1 Règles 18.2 Les données 18.3 Definitions 18.4 Loi Poisson (positif &amp; discret) (par exemble un abondance) 18.5 Loi Bernouilli-logistique (Blogit) (réponse binaire) 18.6 Tools 18.7 Rapidité 18.8 Non-identifiabilité", " Cours 18 Bayesian and Stan langage 18.1 Règles Ne pas comparer des effets de modèles de var réponses diffentes entre eux Ne pas comparer des modèles utilisant des données différentes 18.2 Les données Toutes les variables doivent être mises sous forme numeric Regarder la distribution de nos variables pour identifier la loi qu’elles suivent et les transformations possibles à leur appliquer. Standardiser pour mettre toutes les variables échelles, ainsi faciliter la lecture et comparaison de leurs effets (meme dimension) : cas d’un modèle explicatif. Dans le cas d’un modèle prédictif on veut garder les dimensions de chaque var. Si on veut que les covarariants soient des probabilités : on les borne [0;1] Réduire la taille des données en exploratoire, et ne faire tourner l’ensemble des données lorsque le modèle a été validé -&gt; gain de rapidité 18.3 Definitions theta0 : c’est l’intercept du modèle. C’est dans certains cas l’esperance predite de la var réponse, c’est le témoin. A regarder pour juger de l’importance des autres paramètres. Vraissemblance (totale): sum de toutes les vraissemblances particulières (=pour chaque observation). Vraissemblance totale = nbr d’obs si vraissemblance parfaite du modèle. “la petite montagne que forme la marche aléatoire pour trouver LA valeur de chaque paramètre” priors : Non informatif par défaut : ~ \\(Gamma\\) quand modèle défini sur \\(R+\\), ~ \\(N\\) quand modèle défini sur \\(R\\) On n’utilise pas les données pour définir les priors mais on peut pour borner les paramètres. Il peut être nécessaire de borner les paramètres lorsqu’il n’y a pas d’effet et que la marche aléatoire se perd. Variance (\\(\\sigma\\)) = variance de l’ensemble des erreurs du modèle Erreur du modèle = Var réponse/esperance du modèle 18.4 Loi Poisson (positif &amp; discret) (par exemble un abondance) Var reponse suit une loi \\(P\\) de paramètre \\(\\lambda\\) le paramètre \\(\\lambda\\) suit une loi exp dans laquelle on met les covaraints et leur paramètres pour les faire passer de \\(R\\) à \\(R+\\) nécessaire à \\(\\lambda\\) pour pouvoir comparer les paramètres les faire suivre une loi \\(N\\) Hyperlois = faire suivre une loi à un ensemble de paramètres Qd modele trés chargé en paramètres (vecteurs de parmètres) (pas 1 valeurs mais plsrs) on généralise ceux ayant leur variable associée en commun en 1 (emboités) l’effet nul (theta0) n’a pas besoin d’etre emboité pour etre comparé aux autres paramètres Interet : faciliter la convergence et faire suivre le meme chemin à tout ceux qui doivent le suivre 18.5 Loi Bernouilli-logistique (Blogit) (réponse binaire) logit (=fct de lien) car il faut linéariser les facteurs 18.6 Tools Comparer prior et posterior : ppc_dens_overlay() Validation de modèle selon la capacité de prédiction : loo_compare(loo(mod1), loo(mod2)) %&gt;% kable() Il calule des différences donc le meilleur est à 0. Il faut avoir la valeur la plus haute. Dans le stan file : generated quantities { vector[I] log_lik ; ## vraisemblance pour chaque obs vector[I] prediction ; for(i in 1:I){ log_lik[i] = fct_lpmf(y[i] | theta[i]) ; ## pour loo. ##lpmf -&gt; masse de proba (cas var discrète). ...loi de densité (cas var continue) prediction[i] = fct_rng(theta[i]) ; ## pour ppc_dens_overlay(). rng -&gt; génération de } 18.7 Rapidité Réduire la taille des données 2 chaines et une 100aine d’itérations Ne pas caluler certains paramètres : include = F, pars = “theta” l’argument save_warmup = F (ne pas renvoyer la période de chauffe) 18.8 Non-identifiabilité = vraisemblance reste cste malgrè changement des paramètres, incapcité à donner une valeur aux paramètres (variance trop grande) Symptomes : - chaines ne semélangent pas - corrélations des parmètres En fréquentiste pour pallier ça on implémente des contraintes. Cause : prior non informatif Solutions: centrer les variables (aide les chaînes, et enlève le prblm de corrélation entre param) tirer des paramètres de manières simultanées (par block) (Miltonien) plutot que l’un après l’autre (Metropolis Hastings) sum - to zero contransints : sum de la variance des random effects = 0 Raftery diagnostic : pour déterminer le nbr d’itérations nécessaires reparametrisation by sweeping : ac matrice de covariance post-sweeping of random effects : on écarte les paramètres non identifiables, on ne les interprète pas. on redéfinit l’intercept en prenant l’intercept + variance du modèle "],["conseils-de-rédaction-scientifique.html", "Cours 19 Conseils de rédaction scientifique 19.1 Conseils généraux: 19.2 Pq écrire ? / Pq publier ? 19.3 Les barrières pour écrire et publier : 19.4 Que veulent les rédacteurs ? 19.5 Fonctionnement d’une revue : 19.6 Introduction (3 paragraphes) (250 mots) (¼ des refs) 19.7 Méthodes (pour que ce soit reproductible) () 19.8 Résultats (pas de plan par défaut, voir les consignes de la revue) 19.9 Discussion on discute le résultat tout le long (10-20h de travail 19.10 Annexes 19.11 Les auteurs (les 4 pts validé, international) 19.12 Références : 19.13 Titre de l’article : 19.14 science ouverte : diffusion des produits scientifiques (résultats, données, écrits et code source) 19.15 Data availability: 19.16 Résumé : 19.17 Choix d’une revue (Coopist, “journal selector”) 19.18 Remerciement : 19.19 CRediT/contributeurs : 19.20 Conflit d’intérêt (relations et activités qui ont pu influencer) : 19.21 Gestion du temps 19.22 Gestion des coauteurs : 19.23 Ecriture (qqsoit la langue) : 19.24 Embellissement de l’article (pas bien) 19.25 Lettre de motivation de soumission (pas tjrs demandée) : 19.26 Au Cirad", " Cours 19 Conseils de rédaction scientifique https://docs.google.com/document/d/1Ny_bmW094guCzg8x11Td7pAbqv9EIwCB6iUyIm4WXUY/edit?usp=sharing Cours par : Hervé Maisonneuve (médecin) lire la BD humoristique “carnet de thèse” 19.1 Conseils généraux: 1 idée/phrase/paragraphe 1 phrase d’intro au début de chaque paragraphe donnant l’info du paragraphe Eviter la répétition de contenu -&gt; plan à revoir Les articles ne font pas des sous-sous-sous parties -&gt; simplifier le plan il faut pas trop attendre après l’écriture pour soumettre car la littérature elle avance une recherche non publiée n’existe pas n’écrivez jamais sans savoir vers quelle revue on se dirige la réanalyse…prend du temps citer plutôt la 1ère étude faire d’abord tjrs lire par un naïf avant soumission restez focus dans le sujet dans la rédaction 19.2 Pq écrire ? / Pq publier ? partage valoriser son labo, se donner des “points” -&gt; poursuite de carrière +avancer dans la science former les autres et se former pour faire évaluer son travail 19.3 Les barrières pour écrire et publier : éviter le plagiat mobiliser les sources, la citation expliquer clairement et simplement proposer une mise en perspective l’anglais la procrastination collaboration avec co-auteurs 19.4 Que veulent les rédacteurs ? innovation/originalité dans certaines disciplines la réplication d’une recherche est valorisée clair/simple/concis 50-70% de ce qui est publié n’est pas reproductible 19.5 Fonctionnement d’une revue : peer-review, aveugle ou non (60% simple aveugle (auteur connu reviewer inconnu), ouvert tt le monde connu) Impact factor basées sur les citations rédacteur en chef : pouvoir de régulation relecteur récupère des idées, régule lui aussi propriétaire de la revue a des intérêts économique le lecteur n’a aucun pouvoir car il ne paye pas et on ne lui demande pas son avis 19.5.1 Différents types d’articles : éditorial article revue de la litt thèses, mémoires notes techniques, méthodes correspondances livres, chapitres Article scientifique : - réponse à une question - modèle IMRaD : intro, mat, results, discu - tout au passé - voie active - 4000 mots environ sans résumé et ref - 7-8 pages - 30-40 citations 19.6 Introduction (3 paragraphes) (250 mots) (¼ des refs) Etat de l’art (connu) : contextualiser le sujet du plus général (pas des faits ridiculement trop large et surconnu) au plus ciblé gaps (inconnu) : les manques dans la littérature + hypothèses La question (les hypothèses) Réponse à la question dans certaines disciplines au passé, parfois présent les refs : pas des tartines seulement les plus originales, importantes, pas tt le monde 25-30% des refs ne contiennent pas ce qu’on leur fait dire 19.7 Méthodes (pour que ce soit reproductible) () Sélection (nos choix éclairés) : design, temporalité, lieu, sélection des caractéristiques de l’objet d’étude Data availability : accès aux données Interventions/manipulations/observations : ce qu’on y a appliqué description de l’outil (marque, n°série, année) méthode (durée, temp, etc) investigateurs et la lecture : qui a manipé, combien de personnes, (juniors/seniors) Evaluation : quelles vars évaluées les tests préliminaires peuvent y être mis si courts sinon résultats comment : les stats considération éthique : y avait t-il des régulations le protocole peut se mettre en annexe 19.8 Résultats (pas de plan par défaut, voir les consignes de la revue) au passé pas de ref présentation des résultats originaux, les autres en annexes tableau en priorité (données numériques) (ind en lignes, vars en col en général) figures (certaines en annexe si trop long) la figure ou le tab doit se suffir à elle même avec sa légende texte parle de l’info principale du tab ou de la figure, ne doit pas expliquer les fig/tab 1 résultat n’est présenté qu’1 fois (tableau ou figure) présenter nos figures à collègue naïf pour vérifier leur indépendance la lecture commence en haut à gauche prendre en compte ce que l’oeil doit comparer unités des axes éviter les 3 dimensions, les camemberts, la perspective la double unité est moins lisible mettre des délimitations pour indiquer où regarder sur les photos éviter les noms d’axes verticaux qd on n’a pas de 0 il faut couper l’axe enlever le vide inutile utiliser la police de la revue Les figures : couleurs : couleurs de la revue, penser aux daltoniens et impression noir et blanc (symboles) 19.9 Discussion on discute le résultat tout le long (10-20h de travail passé/présent/conditionnel pas de future pas de rappel de la question répondre à la question (1 paragraphe) (on répète le résultat) forces puis faiblesses du travail (dans chacune des parties) comparaison avec la littérature signification de ce travail (optionnel) (changement de pratiques, nouvelles hypothèses, implications générales) perspectives spin : abus de langage en disant que qqchose marche pas mais que ça aurait marché si… enduit le lecteur en erreur. Les résultats positifs en plus de ça plus représentés dans la littérature que les résultats négatifs. 19.10 Annexes 19.11 Les auteurs (les 4 pts validé, international) contribution à la conception ou aux méthodes, ou à l’acquisition, l’analyse ou interprétation des résultats a rédigé ou participé à la révision critique approbation pour la dernière version engagement à assumer l’imputabilité (droits) pour tous les aspects de la recherche Ordre des auteurs (pas de recommandations, mais de pratiques, négociation entre auteurs) : - celui qui a dirigé l’étude - entre les deux : ordre d’implication - le dernier : superviseur général Si contribution égale : on le spécifie et l’ordre des auteurs on peut tirer au sort Les revues n’exigent rien mais : - auteurs cadeaux/honoraires : n’ont pas participé mais mis en auteurs - auteurs fantômes : ont participé mais ne sont pas mis en auteurs 40% des conflits dans les équipes est dû à l’ordre des auteurs. Remerciements : demander l’autorisation consentement 19.12 Références : tt ce qu’on utilise doit être cité règles selon la revue logiciels : zotero (très bien pour une thèse), mendeley, endnote (payant mais plus professionel) citation alphabétique (en ttes lettres) ou numérique (ac des numéros) communication personnelle cité avec son nom et avec son accord “données non publiées” ça n’existe plus 19.13 Titre de l’article : court (10 mots max) l’info essentiel de l’article (sujet, rslt principal), le message mots clefs bien choisis pour les moteurs de recherche types, informatif, neutres, marketing (jeux de mots) abréviations que si connues lieu mit s’il est important dans le résulat en vu de la littérature (peut faire perdre des lecteurs) humour : pas le même selon les cultures question ? a voir sous-titre si besoin effectif si original pour la thématique running title : titre revient au début de chaque page 19.14 science ouverte : diffusion des produits scientifiques (résultats, données, écrits et code source) principe FAIR : Findable Accessible Interoperable Reusable Dataverse Cirad : dépot de données institutionnel Si les financements sont publiques, l’étude doit être ouverte voie verte : arrêter les revues et publier sur des serveurs institutionnels voie dorée : l’institution de l’auteur paye pour publier (2000-5000e/article), pour le lecteur c’est gratuit (=open accès) voie diamant : “gratuit pour tt le monde”, c’est la revue de l’institution et c’est elle donc qui paye le personnel. Preprint : pré publication soumis ou non, relus par les pairs ou non, ou rejeté après soumission (HAL dépôt de preprint). Risques d’erreurs et de leur propagation, certaines plateformes proposent des corrections et le statut de l’article. On peut citer un préprint en précisant. PubPeer : critiques par les pairs sur des articles acceptés, en téléchargeant le plugin on est informé des critiques faites sur les articles qu’on télécharge Revues prédatrices (surtout indiennes) (14 000) : but de faire de l’argent en proposant des prix plus bas (200-400e) mais un travail de moindre qualité (2-3 semaines), porte un nom ressemblant à celui d’une revue connue, procède par des propositions par mail (ne pas se désabonner pcq c’est pire, juste les jeter), les procédures ne sont pas transparentes. Risque pour la réputation Orcid : open researcher and contributor iD = syst d’identification pour les chercheurs, prévient des cas de changements de noms, d’homonymie, permet de s’identifier rapidement et tout rassembler, fait son CV 19.15 Data availability: accès aux données nécessaires à la reproductibilité, fournir les images originales déposer dans des référentiels de données publics selon thématique se conformer aux normes/fichiers d’info complémentaires, instructions aux auteurs mention “demande des données aux auteurs” ils ne les donne svt pas il est bien de donner accès sous motif d’utilisation 19.16 Résumé : 250-400 mots max à rédiger après l’article clarté et mots clefs objectifs, question, méthodes, principaux résultats (chiffrés), réponse à la question (pas discussion) faire du copié-collé de phrases fortes (hilights) de l’article (c’est pas du plagiat) dernière phrase de l’intro 1ère phrase de chaque paragraphe … qqfois des “graphical abstract” (schéma bilan) (bien pour publier sur Twitter) ou sous forme de podcast mtn ! 19.17 Choix d’une revue (Coopist, “journal selector”) A remplir ! 19.18 Remerciement : les financeurs relecture par un anglophone non émotionnel (thèse oui) 19.19 CRediT/contributeurs : contributions des auteurs et des non auteurs qui remplissent 1 des points (collecte, analyse, recherche financements, consulté pour la méthodo, ressource matériel, supervision, rédac, relecture) 19.20 Conflit d’intérêt (relations et activités qui ont pu influencer) : préciser les discordances entre chercheurs préciser ses opinions dans le cas où ça pourrait jouer (décisionnaire, actif, dons économiques) préciser qui a financé préciser si certains relecteurs sont contre indiqués c’est le lecteur qui se fait un avis sur les liens exposés 19.21 Gestion du temps combien d’heures pour écrire un manuscrit (heures étalées sur x mois) comment optimiser, s’organiser : où écrire : endroit où on y est tranquil, isolé recherche documentaire doit être faite avant et il faut arrêter temps social important pour s’ouvrir Quand écrire : même si la recherche n’est pas terminée ux moments de la journée où on est le plus productif régulièrement (un peu ts les jours) sinon on perd du temps à s’y replonger et ça démotive (dont interruption continue) . Les temps de repos sont essentiels. Ne pas attendre d’avoir une journée de libre, sinon on n’écrit jamais. 25min minimum, 3h maximum (relecture, plans, relire notes, écriture) s’arrêter avec des idées pour la suite (qu’on note) pour mieux s’y remettre effet Zeigernik : on se souvient mieux de ce qui est inachevé que de ce qu’on a terminé, le cerveau continu à y travailler conseils : discuter régulièrement avec les coauteurs pour alimenter la réflexion Procrastination, 6 conseils : 1) pensez au futur, au calendrier, imaginez l’article accepté, etc… 2) apprendre à gérer vos émotions et les sentiments négatifs 3) Diminuer les distractions… 4) Responsabilité : revoir et préciser les objectifs 5) Demander de l’aide, car écrire est assez facile, quand on a appris… 6) Renforcez votre volonté.… de l’entraînement et des ressources et ce sera facile 19.22 Gestion des coauteurs : constitution équipe - transparence - choix de l’ordre - plan des gestion des données - stratégie de rédaction - prendre en compte diversité culturelle et linguistique - éthique - avoir une date limite - écrire sur un drive pour écrire sur seule version 19.23 Ecriture (qqsoit la langue) : phrase simple courte (1 action par phrase) chaque mot doit être utile (enlever : kind of, really, basically, practically, actually, virtually etc) 15-20 mots/phrase pas de style position forte : info principale : au début de la phrase, au début du paragraphe (pas de suspens) utiliser le même mot à chaque fois pour caractériser qqchose (les répétitions c’est ok) les mots scientifiques doivent utiliser que dans leur cadre pas de double négatifs précision : mots, chiffres, totaux, faits, opinions, ref pas d’expressions émotionnelle peu d’adverbe ne pas utiliser des mots indéfinis : it/these/that 19.23.1 En englais pas d’appositions en début de phrase 19.24 Embellissement de l’article (pas bien) sélection de ce qu’ils mettents dans l’article p-value arrangée images modifiées données enlevées salami : segmentation d’articles en plusieurs petits empêche la reproductibilité 19.25 Lettre de motivation de soumission (pas tjrs demandée) : 1 seule page regarder si modèle pour la revue accompagne l’article pour attirer l’attention de la revue mise en évidence des découvertes et résultats importants, des objectifs communs avec la revue on peut dire pq on a choisi leur revue, qu’on l’a connait ne pas parler négativement d’un concurrent ou de politique, on ne parle que de son étude italique nom de la revue et des espèces éviter de parler de notre matériel de travail le manuscrit doit être original, pas déjà publié, pas de conflits d’intérêt liste des relecteurs si demandée, ou ceux qui ne devraient pas relire notre manuscrit 19.26 Au Cirad aide à la publication à la DIST au Cirad “portail du libre accès” du site cirad Agritrop : archives ouvertes (base de données) en ligne du CIRAD Mme Fovet-Rabot : s’occupe de l’archivage au cirad Montpellier "],["distinction-britaniqueamericain.html", "Cours 20 Distinction britanique/americain 20.1 -our (UK) ou -or (US) 20.2 -re (UK) ou -er (US) 20.3 -ise (UK) ou -ize (US) 20.4 -nce (UK) ou -nse (US) 20.5 -ge (UK) ou -g (US) 20.6 -ae (UK) ou -e (US) 20.7 -ogue (UK) ou -og (US) 20.8 -que (UK) ou -ck (US) 20.9 voyelle + L 20.10 Past simple 20.11 Get 20.12 Prépositions 20.13 have got (UK) vs have (US) 20.14 as (UK)/like (US) 20.15 Les dates 20.16 Les contractions", " Cours 20 Distinction britanique/americain Règle générale : Le britanique a gardé l’orthograohe originale des mots alors que l’américain préfère une orthogrophe plus proche de la prononciation. 20.1 -our (UK) ou -or (US) Souvent les mots terminant par -eur en français ex: colour/color, favour/favor, humour/humor, labour/labor, favourite/favorite, neighbour/neighbor 20.2 -re (UK) ou -er (US) Souvent les mots terminant par -re en français ex: centre/center, kilometre/kilometer, metre/meter 20.3 -ise (UK) ou -ize (US) Généralement des verbes ex: organise/organize, apologise/apologize, recognise/recognize 20.4 -nce (UK) ou -nse (US) ex: defence/defense, licence/license, offence/offense 20.5 -ge (UK) ou -g (US) ex: judgement/judgment, ageing/aging, arguement/argument 20.6 -ae (UK) ou -e (US) ex: encyclopeadia/encyclopedia, orthopeadics/orthopedics, aeon/eon, mediaeval/medieval, manoeuvre/maneuver 20.7 -ogue (UK) ou -og (US) ex: analogue/analog, catalogue/catalog, dialogue/dialog 20.8 -que (UK) ou -ck (US) ex: cheque/check, chequer/checker 20.9 voyelle + L Verbes qui se terminent par une voyelle suivie de la lettre L à l’infinitif, dans leurs formes plus longues (conjuguées ou substantivées), les Anglais doublent le L, en américain on double le L si l’accent porte sur la 2e syllabe ex: travelled/traveled, travelling/traveling, traveller/traveler Attention ! To excel et to propel (et leurs dérivés) prennent toujours deux L. 20.10 Past simple Certains verbes sont réguliers en américain et prennent un -ed au passé simple, alors qu”en britanique ils sont irréguliers et prennent un -t. ex: dreamt/dreamed, learnt/learned, spelt/spelled, burnt/burned 20.11 Get UK: get, got, got US: get, got, gotten 20.12 Prépositions Le temps (at/on) : UK: at the weekend US: on the weekend 20.13 have got (UK) vs have (US) UK: I have got US: I have 20.14 as (UK)/like (US) UK: I felt as if I was talking to a stranger. As I told you. US: I felt like I was talking to a stranger. Like I told you. 20.15 Les dates UK: le jour en 1er US: le mois en 1er ex: UK: 4th April à l’écrit, généralement prononcé the fourth of April US: April 4th prononcé tel quel, ou parfois April the fourth. 20.16 Les contractions Certaines formes contractées sont beaucoup plus fréquentes en anglais américain. Elles sont très familières et ne s’emploient que dans la langue parlée (et dans les chansons). Mais il faut savoir les reconnaitre. ex (US): wanna = want to gonna = going to gotta = have got to (ou have to) "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
