---
title: "Bayesian and Stan langage"
author: "Vincyane Badouard"
date: "24/07/2020"
output: html_document
---

# Règles

+ Ne pas comparer des effets de modèles de var réponses diffentes entre eux

+ Ne pas comparer des modèles utilisant des données différentes

# Les données

+ Toutes les variables doivent être mises sous forme numeric

+ Regarder la distribution de nos variables pour identifier la loi qu'elles suivent et les transformations possibles à leur appliquer.

+ *Standardiser* pour mettre toutes les variables échelles, ainsi faciliter la lecture et comparaison de leurs effets (meme dimension) : cas d'un *modèle explicatif*.
Dans le cas d'un *modèle prédictif* on veut garder les dimensions de chaque var.

+ Si on veut que les covarariants soient des probabilités : on les borne [0;1]

+ Réduire la taille des données en exploratoire, et ne faire tourner l'ensemble des données lorsque le modèle a été validé
-> gain de rapidité


# Definitions 

+ *theta0* : c'est l'intercept du modèle. C'est dans certains cas l'esperance predite de la var réponse, c'est le témoin. A regarder pour juger de l'importance des autres paramètres.

+ *Vraissemblance* (totale): sum de toutes les vraissemblances particulières (=pour chaque observation). Vraissemblance totale = nbr d'obs si vraissemblance parfaite du modèle. "la petite montagne que forme la marche aléatoire pour trouver LA valeur de chaque paramètre"

+ priors : 
Non informatif par défaut : ~ $Gamma$ quand modèle défini sur $R+$,
                            ~ $N$ quand modèle défini sur $R$
                            
On *n'utilise pas les données* pour définir les priors mais on peut pour borner les paramètres. 
Il peut être nécessaire de borner les paramètres lorsqu'il n'y a pas d'effet et que la marche aléatoire se perd. 

+ Variance ($\sigma$) = variance de l'ensemble des erreurs du modèle

+ *Erreur* du modèle = Var réponse/esperance du modèle


# Loi Poisson (positif & discret) (par exemble un abondance)

 * Var reponse suit une loi $P$ de paramètre $\lambda$
 
 * le paramètre $\lambda$ suit une loi exp dans laquelle on met les covaraints et leur paramètres pour les faire passer de $R$ à $R+$ nécessaire à $\lambda$
 
 * pour pouvoir comparer les paramètres les faire suivre une loi $N$ 
 
 *Hyperlois* = faire suivre une loi à un ensemble de paramètres
Qd modele trés chargé en paramètres (vecteurs de parmètres) (pas 1 valeurs mais plsrs) on généralise ceux ayant leur variable associée en commun en 1 (emboités)
 l'effet nul (theta0) n'a pas besoin d'etre emboité pour etre comparé aux autres paramètres 
 Interet : faciliter la convergence et faire suivre le meme chemin à tout ceux qui doivent le suivre
 
# Loi Bernouilli-logistique (Blogit) (réponse binaire)

* logit (=fct de lien) car il faut linéariser les facteurs

# Tools

+ Comparer prior et posterior : *ppc_dens_overlay()* 

+ Validation de modèle selon la capacité de prédiction : *loo_compare(loo(mod1), loo(mod2)) %>% kable()*
Il calule des différences donc le meilleur est à 0. Il faut avoir la valeur la plus haute.

Dans le stan file :
```{stan output.var=}

generated quantities {
  vector[I] log_lik ;                            # vraisemblance pour chaque obs
  vector[I] prediction ;
  for(i in 1:I){
    log_lik[i] = fct_lpmf(y[i] | theta[i]) ;     # pour loo.
    #lpmf -> masse de proba (cas var discrète). ...loi de densité (cas var continue)
    prediction[i] = fct_rng(theta[i]) ;         # pour ppc_dens_overlay(). rng -> génération de 
  }

```



# Rapidité

+ Réduire la taille des données
+ 2 chaines et une 100aine d'itérations
+ Ne pas caluler certains paramètres : *include = F, pars = "theta"*
+ l'argument *save_warmup = F* (ne pas renvoyer la période de chauffe)

# Non-identifiabilité

= vraisemblance reste cste malgrè changement des paramètres, incapcité à donner une valeur aux paramètres (variance trop grande)

Symptomes :
- chaines ne semélangent pas
- corrélations des parmètres

En fréquentiste pour pallier ça on implémente des contraintes.

Cause :
prior non informatif

Solutions:

+ centrer les variables (aide les chaînes, et enlève le prblm de corrélation entre param)

+ tirer des paramètres de manières simultanées (par block) (Miltonien) plutot que l'un après l'autre (Metropolis Hastings)

+ sum - to zero contransints : sum de la variance des random effects = 0

+ Raftery diagnostic : pour déterminer le nbr d'itérations nécessaires

+ reparametrisation by sweeping : ac matrice de covariance

+ post-sweeping of random effects : on écarte les paramètres non identifiables, on ne les interprète pas. on redéfinit l'intercept en prenant l'intercept + variance du modèle





 