# (PART) Statistics {-}

# Stats à ne plus chercher

## Régressiosn

+ linéaire de degré 1 : **stat_smooth(method = "lm", formula = y ~ x)**
+ qudratique : 


## Corrélations 

*Une base de données uniquement quantitatives et sans NA à tester :*
baseforcor <- rootsmassMarco %>% 
  select(-var quali) %>% 
  na.omit()

*pas besoin de tester la normalité si n>30.*

*Construire une matrice de corrélation :*
CorMatrix1 <- round(cor(baseforcor, use = "pairwise.complete.obs"), digits = 2) # matrice de corrélation, avec 2 décimales

*avec les p-values :*
CorMatrixS <- Hmisc::rcorr(as.matrix(baseforcor))
CorMatrix <- CorMatrixS$r
Pval_corr <- CorMatrixS$P

*Plot de la matrice de corrélation :*
http://www.sthda.com/french/wiki/visualiser-une-matrice-de-correlation-par-un-correlogramme

corrplot(CorMatrix, method="circle", type="lower", col=brewer.pal(n=8, name="PuOr"), tl.col="black", tl.srt=45, p.mat = Pval_corr, sig.level = 0.05) #avec une croix pour les p-value > 0.05.


##Inférer des données
= Remplacer les NA selon les autres variables

MICEinf <- mice(data, maxit=100) 100 itérations, methodes par défault
*Visualiser les valeurs produites*
MICEinf$imp$varinf 
*Mettre ces valeurs inférées dans ma base* 
Data_completed <- complete(MICEinf,5) ici j'ai pris la 5eme (m) estimation

##Standardizer (centrer-réduire)
as.vector(scale())


## Evaluer la performance d’une prédiction
### Validation croisée (rééchantillonage)
= séparer données en jeux d’entraînement et de test :
*caret::createDataPartition()*

## Processus gaussiens
généraliser la procédure à une quantité infinie de dimensions
*kernlab::gausspr()*
-> écart-type des prédictions, donnant une appréciation de la précision du modèle



